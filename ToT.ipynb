{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "_ScrBRo5USh2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "A5voqrwgHdy1"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    !pip install --no-deps unsloth vllm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "lw23W8R6Hv82"
   },
   "outputs": [],
   "source": [
    "#@title Colab Extra Install { display-mode: \"form\" }\n",
    "%%capture\n",
    "import os\n",
    "if \"COLAB_\" not in \"\".join(os.environ.keys()):\n",
    "    !pip install unsloth vllm\n",
    "else:\n",
    "    !pip install --no-deps unsloth vllm\n",
    "    # [NOTE] Do the below ONLY in Colab! Use [[pip install unsloth vllm]]\n",
    "    # Skip restarting message in Colab\n",
    "    import sys, re, requests; modules = list(sys.modules.keys())\n",
    "    for x in modules: sys.modules.pop(x) if \"PIL\" in x or \"google\" in x else None\n",
    "    !pip install --no-deps bitsandbytes accelerate xformers==0.0.29.post3 peft \"trl==0.15.2\" triton cut_cross_entropy unsloth_zoo\n",
    "    !pip install sentencepiece protobuf datasets huggingface_hub hf_transfer\n",
    "\n",
    "    # vLLM requirements - vLLM breaks Colab due to reinstalling numpy\n",
    "    f = requests.get(\"https://raw.githubusercontent.com/vllm-project/vllm/refs/heads/main/requirements/common.txt\").content\n",
    "    with open(\"vllm_requirements.txt\", \"wb\") as file:\n",
    "        file.write(re.sub(rb\"(transformers|numpy|xformers)[^\\n]{1,}\\n\", b\"\", f))\n",
    "    !pip install -r vllm_requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "240a78ef8491414580fbb74066b0ec41",
      "e8a37cb781d147c0a615a5c3d6715c38",
      "12d0e728ccb54d51befa659fbe5cfd5c",
      "6858fc105ccd402b88d8dbd87af57734",
      "4d82d734c20a45cc9d740f32b31f5f53",
      "c4658df74ee94cd09504d1002e94adab",
      "c473a1153fc243dfa3035c70d205e9a4",
      "d3568d334b024a8c8e5f7aef9f2ab71b",
      "3f57181bc7534b4ba74fc05b54b0978c",
      "14613789a0fc4be9b732082cc35152f3",
      "2ec923444adc4c0bb671d643b640fdd3",
      "dc928ebe41f54be8a74b04515b9af5eb",
      "94dedfa5e35d41a8805d5ec7773b5456",
      "a2f76813ca4547c9a2cc14d04fddfdfc",
      "ad2f8c76fd984f28b1a6efba6f23a00c",
      "9a10132ca99248f9ba154dc7cb6c44f6",
      "8cb0061d60b54c07940d6d3a115848d7",
      "40b1b37d0f0c4dffaaca90d1b0e1fcf4",
      "f2ac8969d3b64b0aa897f3a10a83fc82",
      "a2a8b0bb99f1487d89f5c63ebf5f67e2",
      "24b2a99772f34916b6d991e87aab5fb0",
      "01f0abfbf8de4af7a52ab3792a7f7fe7",
      "df5b5842dd714f719f22ede40ab87ae1",
      "f6a605de6665496ebe49e743e8fabd28",
      "ec4969ae6ae3482e9e43e490d2bca467",
      "83742799fcfa43f0a6a3b0c2169f8e78",
      "5253dee83c3d4b4da137ffdd80fc3e0b",
      "f930b39d0a0142f185d274e02e836d60",
      "c50c0f77f03b4f96895471456a11e56a",
      "92f220a3c1fe4075bbc9ad60b41f99a9",
      "2b8df0ca36be4a6b94cc1c74ccaeedac",
      "d31d891375bc438695b4767f41056d47",
      "6e641ac2a4e94a40bf671deccdeb61b1",
      "83604c8bd2a749d0a141f9be6049f6a5",
      "f7ca319eb2b6435da1247ee627b21672",
      "0e4b1cf1e18d45c390f24465b32b359a",
      "a2e483c7eecc4b58adada732795dfdb4",
      "0202ba174e4d47168ba10019a96a5c05",
      "ae6d37d9ceef4916a586b6fbd1ce8f5d",
      "a379d45a19e94254a76d24ad1de84a32",
      "b8d5462470cf4a208696898eb691c75b",
      "fe15aa80eac24d5d83d7b3c51fcb52dd",
      "e19bc7d784bb4a458a30671fe19c8b1b",
      "471230d33e6d474888edfba9af376029",
      "1e6c10e402db43248dd77af8816e0d64",
      "795766e86cca44c59c245274bbe22f48",
      "6783b517659d4a97aa52ddfcb35f6748",
      "b22d35d8d31243a8953d36d1a1c8e6a9",
      "7e34ec13b074400181fae9c780c51352",
      "b3334a5b935c4ec4b8b09c3c7501ef1b",
      "e2997f4585374b1b89dadfaf81605eb2",
      "86c2445ee4564f40a457659e332e3740",
      "27fbe3b6b7e5406d933c3eb68d1a4b84",
      "bd6b004b2af642509e9904429c480588",
      "b4db15f446a64e04a87eac5ee8b9f5a9",
      "de861e88c6c24c20a7406b71156acd53",
      "87381319e96f428b849ee91148de430f",
      "01a21ef450aa47b9ad34e1930c655a79",
      "b4ee8fd07f6f4723839d39e945947273",
      "268a43e6a2504fbda18c1a5f6a84acaf",
      "8ba705dd38c24c32bc182f5b6145f449",
      "f5c4667ecf484a188bc81f59c70963f2",
      "0b9166e406424acb8f6056dd26982340",
      "ef759f6ae3964e12aa730b0ae0344cea",
      "bda414c7c4784422954448b5144841b8",
      "047e95b34a5d4937937121695f867cd0",
      "81a06bfc557b4557867a941918d3e2be",
      "2b9c643051054ca38204278907123be1",
      "6d99094367b14279b5cc9d06eeefd564",
      "3437d1102a284705af58ff7dd06c83f5",
      "3a0984883ebd4c4bac0a73f0713dcd2c",
      "47eb8c56e9df4bf696c271e9ee82b6f9",
      "a12204d5d74f4c7db633c9a96ba5ba44",
      "5d803474909345cc94f4ba84729d4e65",
      "9fc0603b155e46f3b8240579d1b7961b",
      "aa967edf3c794f56b65545edcb115681",
      "7a5661dfee0b44729778bcdcb2a2654c",
      "ce58d1440a3c436d84a8286be0bbf753",
      "40bd70e827514d3d933ecf8eee4d9178",
      "118c30ed36584e2bb35c32e8b911c7c0",
      "140571cab5b84b3ebd52c94a0b83cb17",
      "e06e7bbc440b4a4088ed81a8585aaf38",
      "05993eca6c704e799ed6e23d4a669388",
      "10c1c59d098c4861b67c632942defab9",
      "a5bb922262d34310942c24eda4a9a4fa",
      "9adc640a2a50443094de2252ed12d9b5",
      "3d6f95ba370d4c72aaea24c8ee0431d5",
      "5af90acebfcd49db84a730233621d851",
      "a8b61f2be9224998857dd7e163f5ecc7",
      "b73b4330ca3644e6bc25f7a110518108",
      "4aef9d57f31c4167a07b9fce8c76f66c",
      "55d3eda2b33b48c28d9eff73b75dbb51",
      "dd61904bf33440958b21a194faf29f93",
      "e53f4ee08afd493b9032efbcd61d54b0",
      "52a751d6c96948da89c8f4d0b93b326e",
      "e5dfe3a4784a4ce7b5e69db5b8bbde87",
      "73bb4b2b601e446e99a15d8575084922",
      "cceb19f0296347e585c820bf337e6ace",
      "9f8ec2aaa176492ebf913ab49480ca8e",
      "7abe33fe5e2340e9acf62cc2f3ab490a",
      "40dbb041274d4b8c864e1881cd974b63",
      "6b6b2dd5a4e842f7828320b6501436cd",
      "e40c250dc8b541c088144f36d374add8",
      "6773a6e29cd34308b6631016240a6f9a",
      "176d337ad8ac460eac3ab1feb40cc7c7",
      "964517c4c73f4d98980bbc2f07e41d8f",
      "be28c890af8a4665a730db09fa47f194",
      "cd0ee443803c4bff91213cd1c6fd63f1",
      "d92dade6612b45628578081e39154e67",
      "e893783b835644e099cd967112e6632f",
      "b8a1736a540646f7b94b42eb3213f389",
      "03ef8dc4901c4e8bacc7dfb3c1806c37",
      "513e3bdcb3d74ddbacaa85598f9bebda",
      "e5196126f51d4f2ea5569d1bde5af31a",
      "f034e3719c4a42a8bb229e28ff0626a7",
      "29716266a0d84d38956b6f49719e4713",
      "b21ed11ec8264f0a939559ca5face455",
      "0ddca1885dfd439f93b2fb235adc6d11",
      "204d998188a6449c9a5e06aabbd4b0dc",
      "1db67132f241441a87402f7b55b71e35",
      "82779cf2c8794603af2c39a4fe857356",
      "db7babce93734aadb3c0d1fe9660d042",
      "b09df958c0614504ad913196d77003cb",
      "fdbdb17ef4964dffb65436dd4590c2cf",
      "90c3dbb567814872b62b13e4e0eb183f",
      "422d8b4de52d4613bc8268c257e76855",
      "61b857deb99846e29f45e92c8c479cad",
      "3d600d3b69f84eb2bd44f8c303bffd6e",
      "f62c406dd70e49db98fbf97001d7e937",
      "b6679d3048b84d7cb66dd06fd1edb922",
      "bae3b4c19d9c401c9d19a9b15c9f3500",
      "00ba8bdc2a2240608689175f430e2e56",
      "6e52fb26e78d4389a31e203aafc30f20",
      "08cb0202ad8a45e49432ead401dbe4a5",
      "34d5b001f0d645b9ae3d798f5534bcc0",
      "5afb11a0abaa4b839bcc103cb9b038af",
      "de66e491b99e472eafd93b837029d0b6",
      "a006493baf9c4674b8b8c2e90a3f1a14",
      "c88f91021d0442b4915022a5b54f92fa",
      "d8f8eb1f01544ef4ad4ea19cb163897d",
      "da7ec7968e9140c38acd43a833358fc4",
      "d67cb7fccc874f13a0388731355c680b",
      "0214746298ed486794f1496b4388537b",
      "764d4689f4354078931f148079e32c08",
      "2b2847cb876b4c76bd8a94d0a4e1421a",
      "cb5659f646524dbea3d8dc05c1f51ef3",
      "f9e31cf73ef54715af9c5cf4be63dd54",
      "4bd21fb567554cb99aa8abdc84b7b13d",
      "6bd948cec0db4ec0ace341fc50ea85e8",
      "2b7b1ee907b44b4993ee042e4aaad8d9",
      "bb900ae0a55b4b17afe0d8f76dd6c299",
      "9d4218d5b31d4b69923834ed28a1f946",
      "09238ebe3ac54c3dbf4e417b2a98455f",
      "ac8909416b544517a92a868bb140a541",
      "33b9ffb7608c4ed9a0f6423e449b3a91",
      "8cfdf2200f024291bd4bf1f6de6f31c3",
      "ecf7c6f1de6c49feb6b50417ba266767",
      "738de307f21f4bfba3368add0772364f",
      "0d3bda9bb14d40739d75125c4cac5308",
      "02d5e3dbb52347179a1f7858dae47f5d",
      "e1a2444564694165a63fb79d92e7c7a1",
      "16fc4ded7da24c3998e44f1e42df9ca1",
      "1285531f138341de929bc513a0ec1e56",
      "843fda0f4c0a4cc791d22df1483b502b",
      "af2263e17ffa428d818576c09d0aba44",
      "71d05608b46f4df2ad41b350394b6c8c",
      "fc4e3b1a609f4f6492f4645d0f2fac02",
      "55cdb6200e0241e4800ca9141c22ad05",
      "5479911bf9e64887989aa1ba006c8e2f",
      "2d738cb35cec46fab046ff004c36e518",
      "4dc4bb9d3988448683a3c3b1f815cae5",
      "a2bc2d9580f34490af36b314546685e0",
      "bff078bfbcfd4f65bef5821ddeab289c",
      "dc6bfcbec1394bf6998323f4f28864bb",
      "4e97959501854d82a38e726110fa9901",
      "0c1f54776702431e91009cc299e74490",
      "432a5be0a15445298bdc7b560ba2b2fd",
      "bb9567f1e04041e5b4b90c108b5a31a5",
      "9df2df1ea6564a048a099b0a375dd90a",
      "e4ede736af9847cf8a129f90a1ef2e2c",
      "04c1158fc5e54d269049c5eea3253332",
      "7c7726ea32e94d389e6df6468a44b6f7",
      "658cfbbb8b0a41818eaae8eef01f1729",
      "63c4c239a47b478db1db38b26e0bd4a0",
      "991aa06ee1cf4aefbd54b3a893c0b2be",
      "e5190004888049c196e9f5ec2d2b3a8e",
      "593cb75039504937a9622e7c56198705"
     ]
    },
    "id": "y8IWjefyH46X",
    "outputId": "e4899f05-0592-4c94-bfd4-303ae39b4ee1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🦥 Unsloth: Will patch your computer to enable 2x faster free finetuning.\n",
      "Unsloth: Failed to patch Gemma3ForConditionalGeneration.\n",
      "🦥 Unsloth Zoo will now patch everything to make training faster!\n",
      "INFO 04-25 21:00:13 [__init__.py:239] Automatically detected platform cuda.\n",
      "==((====))==  Unsloth 2025.3.19: Fast Qwen2 patching. Transformers: 4.51.3. vLLM: 0.8.4.\n",
      "   \\\\   /|    Tesla T4. Num GPUs = 1. Max memory: 14.741 GB. Platform: Linux.\n",
      "O^O/ \\_/ \\    Torch: 2.6.0+cu124. CUDA: 7.5. CUDA Toolkit: 12.4. Triton: 3.2.0\n",
      "\\        /    Bfloat16 = FALSE. FA [Xformers = 0.0.29.post3. FA2 = False]\n",
      " \"-____-\"     Free license: http://github.com/unslothai/unsloth\n",
      "Unsloth: Fast downloading is enabled - ignore downloading bars which are red colored!\n",
      "Unsloth: vLLM loading unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit with actual GPU utilization = 49.53%\n",
      "Unsloth: Your GPU has CUDA compute capability 7.5 with VRAM = 14.74 GB.\n",
      "Unsloth: Using conservativeness = 1.0. Chunked prefill tokens = 1024. Num Sequences = 192.\n",
      "Unsloth: vLLM's KV Cache can use up to 4.88 GB. Also swap space = 2 GB.\n",
      "WARNING 04-25 21:00:28 [config.py:2836] Casting torch.bfloat16 to torch.float16.\n",
      "INFO 04-25 21:00:43 [config.py:689] This model supports multiple tasks: {'embed', 'score', 'reward', 'classify', 'generate'}. Defaulting to 'generate'.\n",
      "WARNING 04-25 21:00:43 [arg_utils.py:1731] Compute Capability < 8.0 is not supported by the V1 Engine. Falling back to V0. \n",
      "Unsloth: vLLM Bitsandbytes config using kwargs = {'load_in_8bit': False, 'load_in_4bit': True, 'bnb_4bit_compute_dtype': 'float16', 'bnb_4bit_quant_storage': 'uint8', 'bnb_4bit_quant_type': 'nf4', 'bnb_4bit_use_double_quant': True, 'llm_int8_enable_fp32_cpu_offload': False, 'llm_int8_has_fp16_weight': False, 'llm_int8_skip_modules': ['lm_head', 'multi_modal_projector', 'merger', 'modality_projection', 'model.layers.2.mlp', 'model.layers.3.mlp', 'model.layers.30.mlp'], 'llm_int8_threshold': 6.0}\n",
      "INFO 04-25 21:00:43 [llm_engine.py:243] Initializing a V0 LLM engine (v0.8.4) with config: model='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', speculative_config=None, tokenizer='unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit', skip_tokenizer_init=False, tokenizer_mode=auto, revision=None, override_neuron_config=None, tokenizer_revision=None, trust_remote_code=False, dtype=torch.float16, max_seq_len=1024, download_dir=None, load_format=LoadFormat.BITSANDBYTES, tensor_parallel_size=1, pipeline_parallel_size=1, disable_custom_all_reduce=False, quantization=bitsandbytes, enforce_eager=False, kv_cache_dtype=auto,  device_config=cuda:0, decoding_config=DecodingConfig(guided_decoding_backend='auto', reasoning_backend=None), observability_config=ObservabilityConfig(show_hidden_metrics=False, otlp_traces_endpoint=None, collect_model_forward_time=False, collect_model_execute_time=False), seed=0, served_model_name=unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit, num_scheduler_steps=1, multi_step_stream_outputs=True, enable_prefix_caching=True, chunked_prefill_enabled=False, use_async_output_proc=True, disable_mm_preprocessor_cache=False, mm_processor_kwargs=None, pooler_config=None, compilation_config={\"level\":0,\"splitting_ops\":[],\"compile_sizes\":[],\"cudagraph_capture_sizes\":[192,184,176,168,160,152,144,136,128,120,112,104,96,88,80,72,64,56,48,40,32,24,16,8,4,2,1],\"max_capture_size\":192}, use_cached_outputs=False, \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "240a78ef8491414580fbb74066b0ec41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc928ebe41f54be8a74b04515b9af5eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df5b5842dd714f719f22ede40ab87ae1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83604c8bd2a749d0a141f9be6049f6a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1e6c10e402db43248dd77af8816e0d64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "de861e88c6c24c20a7406b71156acd53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "81a06bfc557b4557867a941918d3e2be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "generation_config.json:   0%|          | 0.00/271 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-25 21:00:50 [cuda.py:240] Cannot use FlashAttention-2 backend for Volta and Turing GPUs.\n",
      "INFO 04-25 21:00:50 [cuda.py:289] Using XFormers backend.\n",
      "INFO 04-25 21:00:51 [parallel_state.py:959] rank 0 in world size 1 is assigned as DP rank 0, PP rank 0, TP rank 0\n",
      "INFO 04-25 21:00:51 [model_runner.py:1110] Starting to load model unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit...\n",
      "INFO 04-25 21:00:51 [loader.py:1166] Loading weights with BitsAndBytes quantization. May take a while ...\n",
      "INFO 04-25 21:00:52 [weight_utils.py:265] Using model weights format ['*.safetensors']\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce58d1440a3c436d84a8286be0bbf753",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/2.36G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-25 21:01:12 [weight_utils.py:281] Time spent downloading weights for unsloth/qwen2.5-3b-instruct-unsloth-bnb-4bit: 19.430819 seconds\n",
      "INFO 04-25 21:01:12 [weight_utils.py:315] No model.safetensors.index.json found in remote.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a8b61f2be9224998857dd7e163f5ecc7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7abe33fe5e2340e9acf62cc2f3ab490a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading safetensors checkpoint shards:   0% Completed | 0/1 [00:00<?, ?it/s]\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-25 21:01:15 [punica_selector.py:18] Using PunicaWrapperGPU.\n",
      "INFO 04-25 21:01:16 [model_runner.py:1146] Model loading took 2.4392 GiB and 24.818449 seconds\n",
      "INFO 04-25 21:01:30 [worker.py:267] Memory profiling takes 13.35 seconds\n",
      "INFO 04-25 21:01:30 [worker.py:267] the current vLLM instance can use total_gpu_memory (14.74GiB) x gpu_memory_utilization (0.50) = 7.30GiB\n",
      "INFO 04-25 21:01:30 [worker.py:267] model weights take 2.44GiB; non_torch_memory takes 0.03GiB; PyTorch activation peak memory takes 1.05GiB; the rest of the memory reserved for KV Cache is 3.79GiB.\n",
      "INFO 04-25 21:01:31 [executor_base.py:112] # cuda blocks: 6894, # CPU blocks: 3640\n",
      "INFO 04-25 21:01:31 [executor_base.py:117] Maximum concurrency for 1024 tokens per request: 107.72x\n",
      "INFO 04-25 21:01:34 [model_runner.py:1456] Capturing cudagraphs for decoding. This may lead to unexpected consequences if the model is not static. To run the model in eager mode, set 'enforce_eager=True' or use '--enforce-eager' in the CLI. If out-of-memory error occurs during cudagraph capture, consider decreasing `gpu_memory_utilization` or switching to eager mode. You can also reduce the `max_num_seqs` as needed to decrease memory usage.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b8a1736a540646f7b94b42eb3213f389",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Capturing CUDA graph shapes:   0%|          | 0/27 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO 04-25 21:02:40 [model_runner.py:1598] Graph capturing finished in 66 secs, took 0.56 GiB\n",
      "INFO 04-25 21:02:40 [llm_engine.py:449] init engine (profile, create kv cache, warmup model) took 83.68 seconds\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "db7babce93734aadb3c0d1fe9660d042",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer_config.json:   0%|          | 0.00/7.36k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6e52fb26e78d4389a31e203aafc30f20",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "vocab.json:   0%|          | 0.00/2.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "764d4689f4354078931f148079e32c08",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "merges.txt:   0%|          | 0.00/1.67M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33b9ffb7608c4ed9a0f6423e449b3a91",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "added_tokens.json:   0%|          | 0.00/605 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71d05608b46f4df2ad41b350394b6c8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "special_tokens_map.json:   0%|          | 0.00/614 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "432a5be0a15445298bdc7b560ba2b2fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from unsloth import FastLanguageModel, is_bfloat16_supported\n",
    "import torch\n",
    "max_seq_length = 1024 # Can increase for longer reasoning traces\n",
    "lora_rank = 64 # Larger rank = smarter, but slower\n",
    "\n",
    "model, tokenizer = FastLanguageModel.from_pretrained(\n",
    "    model_name = \"Qwen/Qwen2.5-3B-Instruct\",\n",
    "    max_seq_length = max_seq_length,\n",
    "    load_in_4bit = True, # False for LoRA 16bit\n",
    "    fast_inference = True, # Enable vLLM fast inference\n",
    "    max_lora_rank = lora_rank,\n",
    "    gpu_memory_utilization = 0.5, # Reduce if out of memory\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vG7zgIgyH7E2",
    "outputId": "1b442827-4243-4b53-b40d-7f36a4d47c76"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unsloth 2025.3.19 patched 36 layers with 36 QKV layers, 36 O layers and 36 MLP layers.\n"
     ]
    }
   ],
   "source": [
    "model = FastLanguageModel.get_peft_model(\n",
    "    model,\n",
    "    r = lora_rank, # Choose any number > 0 ! Suggested 8, 16, 32, 64, 128\n",
    "    target_modules = [\n",
    "        \"q_proj\", \"k_proj\", \"v_proj\", \"o_proj\",\n",
    "        \"gate_proj\", \"up_proj\", \"down_proj\",\n",
    "    ], # Remove QKVO if out of memory\n",
    "    lora_alpha = lora_rank,\n",
    "    use_gradient_checkpointing = \"unsloth\", # Enable long context finetuning\n",
    "    random_state = 3407,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "DmRALbHZKqDR"
   },
   "outputs": [],
   "source": [
    "# 3️⃣  Build the prompt exactly as before\n",
    "SYSTEM_PROMPT = \"\"\"\n",
    "Respond in the following format:\n",
    "<reasoning>\n",
    "...\n",
    "</reasoning>\n",
    "<answer>\n",
    "...\n",
    "</answer>\n",
    "\"\"\"\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    [\n",
    "        {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
    "        {\"role\": \"user\",   \"content\": \"How many r's are in strawberry?\"},\n",
    "    ],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 85,
     "referenced_widgets": [
      "1a913edc707946178b0598a4c151e019",
      "1dcff39994434c1cb5c82efe042f2c9c",
      "ef0b461610bd416ab3e5c9212cdedf25",
      "be6e552417ed4724ad19c47ad2dfc28e",
      "814af9ab41474117bfe27040e707dfc3",
      "1ee983acd24c4fa7b21f786a4dfaa3a8",
      "8a3e98a0e9c0449c8fe7334414f3ad59",
      "7d886ca547bc40c8adcad51ecd7e11c8",
      "56d08099a329468c820c0d02d8e67a65",
      "54b288edbbd748d38289f428e3ef04a6",
      "c3d57b9100164a3db6679ef879f92be0"
     ]
    },
    "id": "KeOn5O30IGuL",
    "outputId": "23bba283-ada8-41a9-dce3-42ac5c6cec88"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1a913edc707946178b0598a4c151e019",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'<reasoning>\\nTo determine how many r\\'s are in the word \"strawberry,\" I need to count each occurrence of the letter \\'r\\' within the word.\\n</reasoning>\\n<answer>\\nThere are three \\'r\\'s in the word \"strawberry.\"'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text = tokenizer.apply_chat_template([\n",
    "    {\"role\" : \"system\", \"content\" : SYSTEM_PROMPT},\n",
    "    {\"role\" : \"user\", \"content\" : \"How many r's are in strawberry?\"},\n",
    "], tokenize = False, add_generation_prompt = True)\n",
    "\n",
    "from vllm import SamplingParams\n",
    "sampling_params = SamplingParams(\n",
    "    temperature = 0.8,\n",
    "    top_p = 0.95,\n",
    "    max_tokens = 1024,\n",
    ")\n",
    "output = model.fast_generate(\n",
    "    text,\n",
    "    sampling_params = sampling_params,\n",
    "    lora_request = model.load_lora(\"grpo_saved_lora\"),\n",
    ")[0].outputs[0].text\n",
    "\n",
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "68fd026ce1c6402987bf97c3366f87d0",
      "57d85651d4994b7ab3c6678afe59f352",
      "a7ea2e41cbcc4bde878587c2e2d9979c",
      "188e22f046a24811b2afcd66b1c08d40",
      "35bba63fce724d46ac737169c3749b4f",
      "73c9d92c991a4c8b824b3380dc62a884",
      "10f6b52f2a5b48548c8b023b680df4b5",
      "ecd83040e52f44b783a254887b2ca824",
      "277bfd75c70c4eba90de2390feade6d3",
      "ad94d4a5e74241e083c565f24c32f572",
      "c654cf78cb744a5f917c2374f6dabca0",
      "abf73dd3771c4407a502c89322658508",
      "9724b93ca4d540e1a0949348b4cf3a51",
      "6e41fef6d0c843019f1edc624654eb0c",
      "62f867bdf0894baeb44b2220634c775b",
      "55e75902f50d40d68b632aeab5ba6419",
      "4852683157684d2abef1adcc1d88a507",
      "6ae9020beff74522bdaee44457e7f218",
      "70465ec053444f46b7edf8ef27c663bf",
      "683e375401124c01843d1bbed6aa456d",
      "21822847058e4d16b76c66109ebcf37e",
      "2ce2000b17a4461fba67eb787c266371",
      "d6d27c5390e14853abce0ee1f6c3f672",
      "9663f3c250a848f0b13462c4ab641de9",
      "ed6f30db9dd8442fb4d98e7926da6cba",
      "bc3a4c3c36dc426ea587ec1115ca8557",
      "ffad445cbe7844669cb32d95ae2a4b47",
      "4f030ba1f47c48db8a805d8c650d5f09",
      "2f64ae34ddd24b69be14b9148ac87dbe",
      "63b6babd583f4cc9a2b258cf578c4019",
      "e94ceda245b744dbbf24cbd46fcf86b9",
      "dd87ef69580a4fde886cbbc747284cdb",
      "532a83e2847d4d4a803feaa7d1838a49"
     ]
    },
    "id": "jFbIToLoaTZY",
    "outputId": "4f1e5afb-d8cc-43fa-cbdc-312949c75dca"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "QUESTION:\n",
      " Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning and bakes muffins for her friends every day with four. She sells the remainder at the farmers' market daily for $2 per fresh duck egg. How much in dollars does she make every day at the farmers' market? \n",
      "\n",
      "\n",
      "=== DEPTH 1 ===\n",
      "\n",
      "--- Prompt for path #1 (first 300 chars) ---\n",
      "<|im_start|>system\n",
      "You are a careful problem-solving assistant.\n",
      "Grow a tree of thoughts – one thought per line.\n",
      "When you have the solution, wrap ONLY the final answer in:\n",
      "<answer>\n",
      "...\n",
      "</answer><|im_end|>\n",
      "<|im_start|>user\n",
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning a...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68fd026ce1c6402987bf97c3366f87d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/2 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 1 completions\n",
      "\n",
      ">>> Completion 1 <<<\n",
      "user\n",
      "Calculate the number of eggs remaining after Janet's consumption and baking.\n",
      "Thought: Janet starts with 16 eggs each day. She eats 3 for breakfast and bakes 4 eggs into muffins, which means she uses 3 + 4 = 7 eggs. The remaining\n",
      "========================================\n",
      "\n",
      "=== DEPTH 2 ===\n",
      "\n",
      "--- Prompt for path #1 (first 300 chars) ---\n",
      "<|im_start|>system\n",
      "You are a careful problem-solving assistant.\n",
      "Grow a tree of thoughts – one thought per line.\n",
      "When you have the solution, wrap ONLY the final answer in:\n",
      "<answer>\n",
      "...\n",
      "</answer><|im_end|>\n",
      "<|im_start|>user\n",
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning a...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abf73dd3771c4407a502c89322658508",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 1 completions\n",
      "\n",
      ">>> Completion 1 <<<\n",
      "1\n",
      "Janet sells fresh eggs at the farmers' market daily.\n",
      "Thought: 2\n",
      "She has 16 eggs each day.\n",
      "Thought: 2a\n",
      "She eats 3 eggs for breakfast.\n",
      "Thought: 3\n",
      "After eating, 16 - 3 = 13\n",
      "========================================\n",
      "\n",
      "=== DEPTH 3 ===\n",
      "\n",
      "--- Prompt for path #1 (first 300 chars) ---\n",
      "<|im_start|>system\n",
      "You are a careful problem-solving assistant.\n",
      "Grow a tree of thoughts – one thought per line.\n",
      "When you have the solution, wrap ONLY the final answer in:\n",
      "<answer>\n",
      "...\n",
      "</answer><|im_end|>\n",
      "<|im_start|>user\n",
      "Janet’s ducks lay 16 eggs per day. She eats three for breakfast every morning a...\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6d27c5390e14853abce0ee1f6c3f672",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returned 1 completions\n",
      "\n",
      ">>> Completion 1 <<<\n",
      "16 eggs are laid per day. Janet eats 3 eggs and bakes muffins using 4 eggs. The number of eggs sold at the market = 16 - 3 - 4 = 9 eggs. Market price is $2 per egg. Market earnings = 9 eggs\n",
      "========================================\n",
      "\n",
      "────────── TERMINALS ──────────\n",
      "────────── RESULT ──────────\n",
      "Gold answer : 18\n",
      "Voted answer: NO_ANSWER\n",
      "Correct?    : False\n",
      "Mean latency per expansion: 4.24s\n",
      "CPU times: user 10.5 s, sys: 526 ms, total: 11 s\n",
      "Wall time: 15.7 s\n"
     ]
    }
   ],
   "source": [
    "# PrINT Tree-of-Thought debug (fixed prompt)\n",
    "%%time\n",
    "import time, re, string, collections\n",
    "from datasets import load_dataset\n",
    "from vllm import SamplingParams\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# helpers\n",
    "def first_int(t): m=re.search(r\"-?\\d+\",t); return int(m.group()) if m else None\n",
    "_tbl=str.maketrans(\"\",\"\",string.punctuation)\n",
    "norm=lambda t:t.lower().translate(_tbl).strip()\n",
    "def judge(g,p): g1,p1=first_int(g),first_int(p); return (g1 is not None and g1==p1) or (norm(g) in norm(p))\n",
    "def majority(ans):\n",
    "    nums=[first_int(a) for a in ans]\n",
    "    if all(n is not None for n in nums): return collections.Counter(nums).most_common(1)[0][0]\n",
    "    return collections.Counter([norm(a) for a in ans]).most_common(1)[0][0]\n",
    "\n",
    "# search params\n",
    "DEPTH,K,TH_TOK,TEMP = 3,3,60,0.7\n",
    "BASE_SYS = \"\"\"You are a careful problem-solving assistant.\n",
    "Grow a tree of thoughts – one thought per line.\n",
    "When you have the solution, wrap ONLY the final answer in:\n",
    "<answer>\n",
    "...\n",
    "</answer>\"\"\"\n",
    "THOUGHT_MARK = \"Thought: \"\n",
    "\n",
    "def build_prompt(q, thoughts):\n",
    "    \"\"\"system + user + all previous thoughts, plus THOUGHT_MARK ready for next\"\"\"\n",
    "    msgs = [\n",
    "        {\"role\":\"system\",    \"content\":BASE_SYS},\n",
    "        {\"role\":\"user\",      \"content\":q},\n",
    "    ]\n",
    "    for th in thoughts:                       # each past thought as assistant\n",
    "        msgs.append({\"role\":\"assistant\",\"content\":th})\n",
    "    # the template will append <|im_start|>assistant ... when add_generation_prompt=True\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        msgs,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True            # ← key change\n",
    "    )\n",
    "    return prompt + THOUGHT_MARK              # the model continues after this\n",
    "\n",
    "sampling_thought = SamplingParams(\n",
    "    temperature=TEMP, top_p=0.95, max_tokens=TH_TOK\n",
    ")\n",
    "\n",
    "# set-up\n",
    "lora_handle = model.load_lora(\"grpo_saved_lora\")     # load once\n",
    "ds   = load_dataset(\"openai/gsm8k\",\"main\",split=\"test\")\n",
    "ex   = ds[0]                                         # first test Q\n",
    "question = ex[\"question\"]\n",
    "gold     = ex[\"answer\"].split(\"####\")[1].strip()\n",
    "print(\"QUESTION:\\n\", question, \"\\n\")\n",
    "#BFS search\n",
    "open_nodes=[([] ,0)] ; terminals=[] ; lat=[]\n",
    "for depth in range(DEPTH):\n",
    "    print(f\"\\n=== DEPTH {depth+1} ===\")\n",
    "    nxt=[]\n",
    "    for idx,(path,_) in enumerate(open_nodes,1):\n",
    "        prompt=build_prompt(question,path)\n",
    "        print(f\"\\n--- Prompt for path #{idx} (first 300 chars) ---\\n{prompt[:300]}...\\n\")\n",
    "        t0=time.perf_counter()\n",
    "        outs=model.fast_generate(prompt,\n",
    "                                 sampling_params=sampling_thought,\n",
    "                                 lora_request=lora_handle)\n",
    "        lat.append(time.perf_counter()-t0)\n",
    "        texts=[o.text for o in outs[0].outputs]   # vLLM ≥0.4\n",
    "        print(f\"Returned {len(texts)} completions\")\n",
    "        for ridx,text in enumerate(texts[:K],1):\n",
    "            print(f\"\\n>>> Completion {ridx} <<<\\n{text}\\n{'='*40}\")\n",
    "            first_line=text.split(\"\\n\",1)[0]\n",
    "            new_path=path+[first_line]\n",
    "            m=re.search(r\"<answer>\\s*(.*?)\\s*</answer>\",text,re.S)\n",
    "            if m: terminals.append((new_path,m.group(1).strip()))\n",
    "            else: nxt.append((new_path,depth+1))\n",
    "    open_nodes=nxt[:K]\n",
    "    if terminals: break\n",
    "\n",
    "# vote & report\n",
    "voted=majority([a for _,a in terminals]) if terminals else \"NO_ANSWER\"\n",
    "print(\"\\n────────── TERMINALS ──────────\")\n",
    "for i,(p,a) in enumerate(terminals,1):\n",
    "    print(f\"[Terminal {i}]\\n\"+\"\\n\".join(p)+f\"\\n<answer>{a}</answer>\\n\")\n",
    "print(\"────────── RESULT ──────────\")\n",
    "print(\"Gold answer :\", gold)\n",
    "print(\"Voted answer:\", voted)\n",
    "print(\"Correct?    :\", judge(gold,str(voted)))\n",
    "if lat: print(f\"Mean latency per expansion: {sum(lat)/len(lat):.2f}s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "7116d02940a64d328c2a646cf2e66638",
      "d6d6e470a9c941a0a759bb9f95c21d03",
      "df42d183de54419e926d9f41ce8255d4",
      "537cdddaea90407692713b285839fecf",
      "96d10c56856c47bc97d3b5d16be2c580",
      "304a3995cc55420b9663f12510c903b6",
      "eb88f5fdb3af4d56a879e8a7d97ecde1",
      "103e954d3ce24f2c9d67ab4319fc2b82",
      "516885c902c0441d82074f6d0030c9c5",
      "2fc9e40ecc9c43d9bda148ae1a2372c5",
      "5ef062a739f0414b9f97fc695e3c6e84",
      "d06cef870f074f0f98c5e62605a59538",
      "e89e8513fdb9486886d9bbc901198051",
      "f0b19b8c609a4d338341ceb093d18a5e",
      "6a11a5fda68d4b3994a6d6bbaf3f955b",
      "4b5635a4f10a4e4ea48b2e4411844583",
      "72c07af9e7c24abda7556ff259cd30fa",
      "68a0c4d2779d40bb818aaf5c92311f3d",
      "df25dd938a344a0785b07e855f2c6c5e",
      "b3b8ddcaeab74af38f5aa49ffa403fa2",
      "fecf096bb92f4cf098637715e55fa3f6",
      "16efd25276a34cdd9535717205e71596",
      "44fa764b450749ac87f6048b574784bd",
      "8e695cfbf784456a9df1c4a7cd0bd28e",
      "a486705715e6424d88d7111dbf2a3010",
      "725969a4439b47d498d4d459be6254ef",
      "1034c201f1d142178c421eb2660610db",
      "bc4948a09d484a23a4876e034a2eefe7",
      "2f35f130b29f4e1ba6e2ee544f41ae37",
      "b219e732c6df44dcbe03eb76bb18ebd0",
      "3a898d0691514364b873fe0a5046c926",
      "20e1fc34265a4181bd71bec87a57da37",
      "218d10cfb9a74ae9b876a264dbdb2cc4",
      "4b2f2d45127a41a0a1e39869a362ea5c",
      "97d368c1a5e642c9a4270603a692d65b",
      "0d9a1813cca64ee8963cd59c799624a1",
      "4072ec59fd884806af55c0d983e64eda",
      "3f5942584ff946619c7a3477f11fe295",
      "42a937f8117c4822b37355c309ba1b3b",
      "62d26d2d1ace486d823c698b5dd7e4c8",
      "fc9f9c0827b74bac9820479c359a4c49",
      "1f9e48036119407d94a629bea1937c2b",
      "ade10421fe6b42be98847e480863ff20",
      "64cabfea6e30462db780f236a3d270b6",
      "80f61c9217a74268805d2fe8763a7a02",
      "bbc17aa96e6b4ed48b8f3b0698577ce9",
      "893cdd367a1141d1b5bbf98027057fa0",
      "d5809199aeb144e89a72d93de1dc37df",
      "ddf92d657eac4fc6bafe611805720a1b",
      "f5d25a940a094195b31d282813b997fc",
      "ce38973740df49d4a26d70c8a021ca87",
      "04f2fa94c96349a084d725614be0bc82",
      "d9b88446b3684e7ba1e90165ed7d1fef",
      "656141277ff8447a94ed2072cc8ace8c",
      "4575ba26133247b58806a957c195d9fb",
      "9a3600544ee54ab2b3bd026e6f20da54",
      "af8dbf9336a04c00a38c7b98f711b789",
      "3e3f35ac7b4047c4aa737ff15cca7d77",
      "42337b3d70cb43239405b846124e8f88",
      "5b45b5d0471b41ea8bf2b8f7f86b9f2e",
      "5e4577c7a7bd4cf1981c4e758173c5d3",
      "860d9561e63c47348abf2a5375c76473",
      "7935d3a388f147fe91487dbec978e222",
      "d064a7cb7f094b4da28c2a23871a6301",
      "b43b2a32e51142d298ea5cf4c85a08fa",
      "435533584eba45abb44457105965b168",
      "849579291942416f99be79c80e6b8412",
      "82f7040b15504d5f95bed76e0c2c893b",
      "2e905b6e3681465093b4ef662b9b019a",
      "f6d3d3aff33f4026bed38da04bfa376a",
      "28e581de70e443b78ac331a448ba7a51",
      "cbd20ee67d5b48d88b030d8b48264639",
      "84bd789d8b5b434a9958c0052640aeb9",
      "bef27d3f126a4e18a95bbce46b8ad88b",
      "26038ba04e6746f1879f0ec250537a51",
      "9562ec9b366a4fba962dc02c6ccfc9c6",
      "be4e3655b2e2408fa79b17e17554ff26",
      "87b300725d254e40be48352b50f5a20f",
      "74f59af2fbac49c69508297581c93774",
      "ee0a2f2568e5469c8927ba5db85ddbda",
      "52d4bede16c040b7b427b79a022ac4f0",
      "a022132e1659441ebc3a456ef220358d",
      "cbf94a77774e47f3a119db9d7833e6b4",
      "cdfac018c9724b78b3f209a0f87d94cf",
      "8ea156dc850c4811a5bae603129565d3",
      "5cdb8784a6bc455c96f014193ce113bc",
      "b8206ca0529b47678adcb8ec18990083",
      "02d91a51c45041d789b8e6cffa867dd3",
      "65ea0874a98348e6ba1138e4eb092801",
      "c60ce3374cb84edbbb292ac21a340865",
      "c202b2d231044ef29fb941306d6022a6",
      "2e4eebb0e161408a80d60c1a1c90f553",
      "becd218b93604ec3b1f98c91f1748734",
      "39b2ceb141824340998dafd325d4e270",
      "9218fea1dd7746f1a2c206efe8c4c41b",
      "cf5ee589d482457697bd1d73e0b1aeb4",
      "16ef79b5277d43018387eb37d68443aa",
      "6acd9bac00f348ada41de8e76374fe09",
      "78086130d69c44dbb991b21b78b5f7c9",
      "9885ba3231294ce6925fba56ef474eab",
      "4ef6937aad314a74beb9baab9be65a87",
      "a83791f4b7f24eda8454115797048982",
      "82ac259f0e404c7d9f99bc07652217be",
      "a303b703545946159c8ab09fd25d257e",
      "e6b2c9076fbe403094f8ccb5a1c98a70",
      "d2dc1824a82c49e49e8803ebb4d29d9c",
      "dbe918c111c049e89614faa592e68360",
      "c95c971d89204e978e936f0dc3cc5aa9",
      "668be6e9afcd4bce86da293bb8df05f9",
      "315e2281b4694313aeb77988dff5a12c",
      "6c7cd89352244a109742493e0f4a562a",
      "d31d728da6834bb3a5674ed06b3bdf05",
      "bcce722005544e2bb856d07c8d4b9afa",
      "2dc9fa5961394c8abc789c930cd31b08",
      "8346cd96a16e4a608bf98bb7bc870501",
      "578902b501bc4755b46ccb5e8caef219",
      "fbce0268b88a4ac596626a4e7f05f45a",
      "5528a547db21490b871a8c62b3179d12",
      "f877147f1799485ab7cd48ff8c3e6101",
      "0fcb010c1b2343a089a90b5b7da984d0",
      "dca022b65bf142d19475d37c89efd9aa",
      "7cdac03a4ed840399a289f74cdcd02bb",
      "13b392511ea044e5803cd7ae647e933c",
      "597ef89712884cf9824705debd2d757e",
      "e210b76e10834998ab47195f30104a96",
      "3e463be3a0fa471985411b00c4aad60c",
      "fb62e03e70b74f95b08808e5b8af28b1",
      "f7e9b8c224a84552b18cb1811eba039e",
      "b99a126bdadc408d8fd3851242f6a7c5",
      "0494cb3b2d0043dfb477748062e71027",
      "b4e2378045ae49f4b0fc206d7026a75e",
      "56ab0f4c42ab42269eff067ade97053d",
      "781d4e49f1124f2580374b4f501bc52c",
      "156c5442d165428e8b61fbcf5c41ade4",
      "77c49fa97d78412ab0e16f84ecd8f6d1",
      "c6c3c247f4af4e29b392c79521f35b3c",
      "c50803640d5244188bb87a4141a0b1e6",
      "50eb266301e14ecf864a7932ae1b754f",
      "55771fcd8297482b9940c8204679cabb",
      "af2f77c7ee154949ac3759d9613e2ec5",
      "728016975cd24143be008bc45e537632",
      "46184b542ea24311ab4b1b223b8f4ba5",
      "0926105d86f4428b93f4f5eb12fdea38",
      "c6ecb5952b2d4842bb675d3bfff99e39",
      "9e4f9d9a31c94fe490345e1825164f05",
      "f8fb1780138c4f10816f19e1ba978c86",
      "d2c827a8008648c5aa2994098f9f3b65",
      "3984442548ad4057afb9b4be608b7f30",
      "2a92b71fe24943c09adc86e7cdb6d027",
      "04903055c0f34004adfed10b0480eec2",
      "a32db02f719e4d5ab5a455331200c833",
      "7794aca339fb466baf6c0d22284a77d6",
      "3cecaa6817a04c679fa27ff124128a90",
      "f6661801e140449a8129f2d8fabf29ef",
      "cb68b744851d4a12b4092ae5b8c368e5",
      "dde804bfd27f4278ab4d0a50173fc74b",
      "d7ff75dd47f9417289bba5bd3a47ab5e",
      "781278e3a9de48c6aed8a53de6d97539",
      "c2bbf533344b466f8e4a5e5467343a29",
      "cc934dd94fb946cd8fd7e1ccca6c96fe",
      "fe9db19f2db7413c8b7b52e69a8bd22d",
      "0a6274ec4d9b487eb36fee54c7bcda3f",
      "f1c5faaf32da46478df9f03919ceaabf",
      "27939d8e996e44a4a2a98894b0399e7d",
      "0dcd3976f798474c8b107245ba8ea5ce",
      "7577d7f5ce1842d2bf9380a0e5a61001",
      "ba0bb8fe57af4ff0a1de3a52d3762100",
      "8737e824b6db49dc829e220a71ae9fe7",
      "4e113285bfda401793652c0a76b50dc2",
      "760b5a8cfd104c9bac776351d54f0826",
      "ffc7d4d334814314bddbca92541a0849",
      "78bf6908e55a4b189e2a22cf1835346f",
      "efcb7284f3214db39f1c49f86a97ff17",
      "0387b8db09ed4cb191ba69fa9315e482",
      "2c14c8913ad542eca42a087de989e905",
      "27fdfc40f0574871a3213ae1f6e66be1",
      "c3e98537bda948d88b9ac819e8c4067a",
      "0097bf2bf605467a9cfd9a2d5deaabac",
      "080a48a75e7c419e952b3ae8f528c7f9",
      "6a79373eb3954e9392419be7d59cc4f7",
      "2b865b7509a844c5876a5d7e453a6a9d",
      "f265a3ba422848b4b59479f06621a262",
      "4adb26dd0333457dacc9805ad787ee01",
      "3f54a8a857a7425ba5f78384c1e3107d",
      "ea23fd62d37b43b4a7ebc4062777e9bb",
      "cfae08642ab04954acc3896feb06e226",
      "68a240b7236f4966a39894a65e0db6f7",
      "2c1107632fe2409f8e4c3ddbb205733a",
      "702c3d7d07fb462e88b815dd38d63872",
      "f41f3a0424794d0daf38e37a5b50ecbb",
      "636cfb8794e44d8b9f241be0a2ff7417",
      "7d63d921d4764636a8598bd2a55237f0",
      "1b65733cf7b047f29c5a93fa6ae8bdb0",
      "d979c2aca1fc47e490ffdf6be8a6f42f",
      "a00da6ac72aa4a8bb7210b735bebf654",
      "8721ed5d4115444198eb8318b8216305",
      "860070661559492ab1ffe4f04e0f9869",
      "6c492d0dc5ad4c53b478cb2b3c4da406",
      "39db640a98dd4058a06268862c5656d8",
      "e3656207aef346df896cca84c75491d7",
      "995e39654d704778b7bc6b97b67374f5",
      "f329105315d6453290ed24afc208979b",
      "39f61a2edaaa4a82885ce8b5c90db709",
      "d7c721a01fd045c58dc4bd779d9a38e8",
      "c16ce3ca49ea46bbb598f5ef3c8309fd",
      "fffa079926fe4aa88909313c1f84fac2",
      "b32b40e89ecb46adb48dd1b727bece72",
      "8a433cb9025848e5b87a6b6082edf0d9",
      "81d389e0cb9b4b29b6eec499ceff92a2",
      "5e57324e611a4b489e7fad1f0987b08d",
      "42b836a384814bfb8284580d48632ded",
      "df190ea8318947db86d0f75dcb21c88d",
      "aac68f8b41c24ceb8e3e91e74f9c22d3",
      "fc09ec233cc24b69ba101f511959fbeb",
      "dfaa470a548c4ef6a70e872ed9cdab5f",
      "5b0798ae9b16429e8f63cf7021547afe",
      "1051a1645a5c4fce9c022268bf2d9a4b",
      "409e6725a35a477cbe709060636b627c",
      "13472a366d434f7d9f9ed3f0d311cffb",
      "b4573a2a4f5b4396a240170e96f51f9e",
      "6fe9caae74174f57ac17ee4cd08ddbd2",
      "bc0d9ee6a8014c61b56d2521dd00e067",
      "2d02b51a37424677b72b0762360a22cf",
      "0f2911466da14c969cffb5c3a473044b",
      "79d977adc7a844008263e992add9e652",
      "3bd9be93be1e40e79a7c9a8657ce0582",
      "5a369976b57b4a88bc9b7773e232990c",
      "95fed15d3e59466296e63ca64c5f910d",
      "6b4a64df7ab74b9088ad1725247da8a4",
      "98f6c1f060f84ed8a66e510e4bc49ccf",
      "df2facd8193e4e4bb1e58123da6e7a54",
      "07c85b16d1ca4b26b7188d40b29d7ddf",
      "0ae318ac77d34754b1ac02ac1c959598",
      "27fc6473a9584df0989034465c1858d2",
      "89c0f9fecd904f5eb8d967f36edb021b",
      "294f8be9f8984c409ee9c97ce8f60979",
      "ca95419cfa024f3e8624d36a62cb9fd1",
      "55f02c61d63b4a3083f09a8b3bb4f8e7",
      "6e7ef004cd134c768ce8adcc99bc6b51",
      "04ea95ec764449399ccf45109c258ac3",
      "043a8658056c4ae5bf49b80535a10ddf",
      "38a1faabbdb24ef99dbf46c121a31081",
      "d8c762d8ee594a68843724f17b744d9b",
      "0eca93582017467b8da409f9ef5c6c4c",
      "57ff173a26a64f23b1b30141b6e9c208",
      "dbda37aadba94c06a921295d52c67c2c",
      "96fad8c2ba7c4196a399ae39cb45f891",
      "7089dff8c81f4295b15bef6da4eff64d",
      "28c14e0eb0bc45f29c80bab9e8a477d4",
      "58c60139c607427787600ea3262fa2e2",
      "11cdc991320443ba8f64cd3ef3f46831",
      "c5c8530515a7456690f67861a9de54fd",
      "cee3a4b3b6454451ba478f6c3f55b2c4",
      "1f2c9d4b7c5146b8bfaa4727cb578eac",
      "f18956b65a0b4b5e946b47bd023009cf",
      "d27893e3a7814f6a871a661f06e45dc8",
      "dd5f32ee04b2491db0192501f595f25c",
      "30604afde8424799891555c05ac48511",
      "ec07c2665c944d588b0554a6625be055",
      "a27dff2c4f9a4579b0d4f8e553456c00",
      "58c2b84f188d4748a349c4390d217289",
      "ead3c58b41e4463dbdc4e7ce9583a49f",
      "90e5e163872c45b5aa0e12b478bd14c2",
      "ad9eb4b2f9bb4aeb8bfd6ba7c62f840c",
      "0b3d0fd13c4a4f789513136b9adbc39f",
      "f51d2e7b6e274e4980c0854484cbee13",
      "309394c5d70e4b8a97abdb43f61d281a",
      "43325eaa3afa4bfaac52318051c0f5d5",
      "6a0691fb83714aa28bec8dae31bc3708",
      "777bb6e71e654bf98840539bb72e3a62",
      "db141b58998a46a9b76afd650107f7e3",
      "e25173ccac5b42ff92886cd8025f0bc9",
      "7058bf85dc11428ba6afb0ed93e012b3",
      "be3392f36add406b88cb430f4630463e",
      "4e47eba1565444f1a9b35893635bd0c4",
      "8152522cceed43dea8d393c433690f62",
      "e424948409d3477b808def7439062004",
      "a098f2a5fa834e258c6fa5be00b4dfba",
      "93fc96a68a8b401fbb92266b11c945d4",
      "654b8ec1a1934207a5264bb4f1cac493",
      "f9ff79b3f484499b857658410de59e8e",
      "62621ba4cf014378b8624f2c39f680b5",
      "5bb8e42a5cf4407eaf31d5f80de55472",
      "fee2ce54fe4d43f3bb10c9b0a4e8d065",
      "aa8030eb66fc48139ec7b095181e5268",
      "90536a8e69844a0880a08039f3d64b13",
      "24ff9aa425194bab8f2445ec2f04425b",
      "dfdd84feaca446e3aee0df8f91fcb79c",
      "c5fa80ba266d4fc9bb2035226a7e2ed0",
      "a1528880daa1460e986dbb49b8cfebfd",
      "31d70b62825841fb8e8f4ba377cf20ab",
      "c0509dda08b84050959143798afac142",
      "febae92c55f141b2bb6d36885892183e",
      "85c7ef2dca1347ddb5d42103ba36d8a6",
      "3403997bdbf2400b9ebf2a7952a0c4da",
      "b401ce654c664ba5ac4b366e956d0a2e",
      "7487504a757f4e2d8cc1498541a29f69",
      "5d94cfa2762d46b98fe475814115227d",
      "3936b153f9e24c169dab377950c34d7d",
      "5bbb18c430d7417096372d7aea913a0e",
      "ed232ec18cf2459dba8ec27915e7af86",
      "71b5ee016e0148268b38b337bc82e67d",
      "0d642359201c459cafc73b29e745b8aa",
      "4231fa83458e4f458a0b1f0968e13770",
      "d81dbf1caa6b41eb8bb51e0ab9594465",
      "92f23bcf815c463eb9a7eb8635520f5a",
      "35212e6bf6664be0a6d42e90fe08f79a",
      "676f54df6b3a4db097a51f1500ea4c0e",
      "7cc6d0667ce54f1ab9a7d476672cde61",
      "ab05d58e47ca44f19352831b31f6bfb4",
      "861a0bcb940c4f378253e50c08937360",
      "6cb6cf1150b74a5e9123f87eed1e0f3e",
      "269efa76bf0a4506a7182b68b2f53a4d",
      "3a3dbbbd2f214869b9aee724f1162bdb",
      "4f8d2a98de194d058454b601174b1ace",
      "2ba42b7b438a4817bf8fa44ff023d887",
      "e370830323014caba9c297fa961ef3b4",
      "b40fec69dee2431297ee8e0e01c62735",
      "acdeeb13b3a84873a35dd74ab6fbc5e5",
      "10a9cb7cb7cd49b88663547af5ddff59",
      "410e8e7aaf13491eb59d6fe2ec7a0b19",
      "e059934f239246da8c11955ebf013923",
      "3e16a0e4526849609c54821b0c26acb1",
      "8de34bd0ed33441ab882651ce0b63c82",
      "4820b51c74b246b29bbf65eacc93a20c",
      "b1d2eb49dc0d4de68474242e34a57b7e",
      "66cbf53e143e4424b1477ac28d5d697b",
      "78501d75a977468e86a41708ee16f82a",
      "ca66f4df725d40fba3cf6c1830118c33",
      "f85775c60dd842d9a47835c20358a89b"
     ]
    },
    "id": "gYaVb-CcanPK",
    "outputId": "4458f71f-4661-45a0-81f5-0af54dd978c2"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7116d02940a64d328c2a646cf2e66638",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d06cef870f074f0f98c5e62605a59538",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44fa764b450749ac87f6048b574784bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4b2f2d45127a41a0a1e39869a362ea5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] gold=    18  pred=      18  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80f61c9217a74268805d2fe8763a7a02",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a3600544ee54ab2b3bd026e6f20da54",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] gold=     3  pred=       3  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "849579291942416f99be79c80e6b8412",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "87b300725d254e40be48352b50f5a20f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "65ea0874a98348e6ba1138e4eb092801",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] gold= 70000  pred=      30  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9885ba3231294ce6925fba56ef474eab",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c7cd89352244a109742493e0f4a562a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cdac03a4ed840399a289f74cdcd02bb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] gold=   540  pred=NO_ANSWER  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "781d4e49f1124f2580374b4f501bc52c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6ecb5952b2d4842bb675d3bfff99e39",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb68b744851d4a12b4092ae5b8c368e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] gold=    20  pred=NO_ANSWER  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7577d7f5ce1842d2bf9380a0e5a61001",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3e98537bda948d88b9ac819e8c4067a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c1107632fe2409f8e4c3ddbb205733a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] gold=    64  pred=NO_ANSWER  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39db640a98dd4058a06268862c5656d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e57324e611a4b489e7fad1f0987b08d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6fe9caae74174f57ac17ee4cd08ddbd2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] gold=   260  pred=NO_ANSWER  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "07c85b16d1ca4b26b7188d40b29d7ddf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d8c762d8ee594a68843724f17b744d9b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1f2c9d4b7c5146b8bfaa4727cb578eac",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/10] gold=   160  pred=NO_ANSWER  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0b3d0fd13c4a4f789513136b9adbc39f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8152522cceed43dea8d393c433690f62",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24ff9aa425194bab8f2445ec2f04425b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] gold=    45  pred=NO_ANSWER  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5d94cfa2762d46b98fe475814115227d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7cc6d0667ce54f1ab9a7d476672cde61",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10a9cb7cb7cd49b88663547af5ddff59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] gold=   460  pred=NO_ANSWER  ❌\n",
      "\n",
      "Accuracy on 10 examples: 20.00%\n",
      "CPU times: user 54.2 s, sys: 212 ms, total: 54.4 s\n",
      "Wall time: 57.8 s\n"
     ]
    }
   ],
   "source": [
    "# Tree-of-Thought evaluation on 10 examples\n",
    "%%time\n",
    "import time, re, string, collections\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from vllm import SamplingParams\n",
    "\n",
    "# helper functions (reuse if already in memory)\n",
    "def first_int(t): m=re.search(r\"-?\\d+\",t); return int(m.group()) if m else None\n",
    "_tbl=str.maketrans(\"\",\"\",string.punctuation)\n",
    "norm=lambda t:t.lower().translate(_tbl).strip()\n",
    "def judge(gold,pred):\n",
    "    g,p=first_int(gold),first_int(pred)\n",
    "    return (g is not None and g==p) or (norm(gold) in norm(pred))\n",
    "def majority(ans):\n",
    "    nums=[first_int(a) for a in ans]\n",
    "    if all(n is not None for n in nums):\n",
    "        return collections.Counter(nums).most_common(1)[0][0]\n",
    "    return collections.Counter([norm(a) for a in ans]).most_common(1)[0][0]\n",
    "\n",
    "# search parameters (can tweak)\n",
    "DEPTH, K, TH_TOK, TEMP = 3, 3, 60, 0.7\n",
    "BASE_SYS = \"\"\"You are a careful problem-solving assistant.\n",
    "Grow a tree of thoughts – one thought per line.\n",
    "When you have the solution, wrap ONLY the final answer in:\n",
    "<answer>\n",
    "...\n",
    "</answer>\"\"\"\n",
    "THOUGHT_MARK = \"Thought: \"\n",
    "\n",
    "def build_prompt(q, thoughts):\n",
    "    msgs=[\n",
    "        {\"role\":\"system\",   \"content\":BASE_SYS},\n",
    "        {\"role\":\"user\",     \"content\":q},\n",
    "    ]\n",
    "    for th in thoughts:\n",
    "        msgs.append({\"role\":\"assistant\",\"content\":th})\n",
    "    prompt=tokenizer.apply_chat_template(\n",
    "        msgs, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return prompt + THOUGHT_MARK\n",
    "\n",
    "sampling_thought=SamplingParams(\n",
    "    temperature=TEMP, top_p=0.95, max_tokens=TH_TOK\n",
    ")\n",
    "\n",
    "# load LoRA if not loaded\n",
    "try:\n",
    "    lora_handle\n",
    "except NameError:\n",
    "    lora_handle = model.load_lora(\"grpo_saved_lora\")\n",
    "\n",
    "# dataset slice\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\", split=\"test[:10]\")\n",
    "\n",
    "results=[]\n",
    "for idx,ex in enumerate(tqdm(ds, desc=\"Evaluating\")):\n",
    "    q     = ex[\"question\"]\n",
    "    gold  = ex[\"answer\"].split(\"####\")[1].strip()\n",
    "    open_nodes=[([] ,0)]; terminals=[]\n",
    "\n",
    "    for depth in range(DEPTH):\n",
    "        next_nodes=[]\n",
    "        for path,_ in open_nodes:\n",
    "            prompt=build_prompt(q,path)\n",
    "            outs=model.fast_generate(prompt,\n",
    "                                     sampling_params=sampling_thought,\n",
    "                                     lora_request=lora_handle)\n",
    "            texts=[o.text for o in outs[0].outputs]\n",
    "            for txt in texts[:K]:\n",
    "                thought=txt.split(\"\\n\",1)[0]\n",
    "                new_path=path+[thought]\n",
    "                m=re.search(r\"<answer>\\s*(.*?)\\s*</answer>\",txt,re.S)\n",
    "                if m:\n",
    "                    terminals.append(m.group(1).strip())\n",
    "                else:\n",
    "                    next_nodes.append((new_path,depth+1))\n",
    "        open_nodes=next_nodes[:K]\n",
    "        if terminals: break\n",
    "\n",
    "    pred = majority(terminals) if terminals else \"NO_ANSWER\"\n",
    "    correct = judge(gold, str(pred))\n",
    "    results.append(correct)\n",
    "    print(f\"[{idx+1}/10] gold={gold:>6}  pred={str(pred):>8}  {'✅' if correct else '❌'}\")\n",
    "\n",
    "# ---------- summary ---------------------------------------------------\n",
    "acc = sum(results)/len(results)\n",
    "print(f\"\\nAccuracy on 10 examples: {acc:.2%}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 586,
     "referenced_widgets": [
      "0ff6acec96154856932ca0984b478e23",
      "0bad9ce7596244c8b5ae6f4bf9b17818",
      "ce5d2b94868c4ed384475b22db79995b",
      "ad9894a7502e4893bdb63f2d62240b8b",
      "e2908b7fdd13487c8a0feb54137f2601",
      "417676fe657347099e6872f16d797586",
      "cdccd3dac6e649fca94d277a337ddcac",
      "9190efdadcc14527aff85cd5f370299e",
      "a27dede0bf194850aab6a3fd2532923e",
      "47c838e37cfa4dc0b6ea4627128a8abd",
      "20a94d92c2eb4692a5211be7292990ee",
      "7540828b4a1d496a93ca4e5730d643d4",
      "bb5062cc8bbe48048519ea7989247895",
      "090ddcafa95840d5afb464ec0c326815",
      "0934c2a7a2d24164bc6cdbe9c4c8832a",
      "4dc1ad90dc8d4a2aa441636c48a9e863",
      "93ba9d7c79764121a0c4eab7f9c4c1cd",
      "333af5d11e2b4a9081ad3c77bc5a2004",
      "accffe0f665d45b9ad037f2703767ea6",
      "71af3a73797648c58737dc310433e714",
      "fc658c66d5f745f7941d5dc64e9cc97b",
      "6decdb002e61453995cc3be25b97d7c9",
      "c074d2a0cbca46119d90ba098715c9be",
      "aeea7b2d1e2348979f04b0b865590afd",
      "33b276bccb004d7a9742a6196b2429f7",
      "eef3c8ed3d104987b92f97c9f45b090b",
      "45339ebe36ee48cca9627c3a66980466",
      "3adf2c550ba44a7fbbdb009e7040d804",
      "a9002060da834352877d27e4d3c96ed9",
      "fc987ee0fa0a48bfa50f96c0a57088b8",
      "e42ebbf7e93340639aa3fc9b5a8345b5",
      "fbbc758d0edd4447973d303d95db20e1",
      "566a0761787a4331b288b81347c5b592",
      "5aa9fbb4f5ec4cb880a2ee13aab7483a",
      "a4548259d8b44dd89de06791343fc3bb",
      "a2416e07abe1490192feae658886919d",
      "b0a7714ef4ca4405811f39ec41ea31b4",
      "68d702270ffd43b0a665c33de1c684fb",
      "83b91a4d9821413faf2873ffd865e70f",
      "a2df4d8342a446039bd838c1d78a2aa3",
      "1cb87de3135f457b819d06b8ff15774f",
      "d45dca4bd4bd4dcd93bf0af13abd3cfe",
      "85d8672005014012a436884d5f107939",
      "0aca3f88ab9a4e7ab3f173644dd9bf70",
      "ce2a49279a7341deb0f20d5493782653",
      "10a8d205b70f41ca8820cf9f508ad770",
      "7e4c51ed192d4e58b1f2c009ccebea73",
      "6e29eabb4a7e409b949b525d189bb081",
      "fecdd6f40e644aeb913b9320004719dc",
      "d03529bbf3944a489c0398d36379a188",
      "5858b0cdbf1e46b39939db0949c1466b",
      "bb4b50fc4bc549db97b035ccf9c650f1",
      "96f9802580c64aae9ba636e0e68f73e0",
      "6875e972644c4a699ac0a48dd19575b4",
      "aa19c22cbd424657b1fe233884c6b61b",
      "ec528f60c5d142359a9e58301bba3535",
      "6ef603d7e6c64689bac1e6316be98a47",
      "85d87b2ef51a4fda93a80b09207cf590",
      "4c18f3b222fb43d6a7762c630c179092",
      "bc83c6223c2e48ed8b1bc131f39eb744",
      "85937e107a08457ba3c8f0e98c471769",
      "4f44db5dfde54bc68fac27f4e6034a47",
      "002536f461e44332a3f7b1057734b1af",
      "7f49b9e7f81f41ba9f99293a1de01d98",
      "c770a5c11a4d403e95e9e641cf1c15c1",
      "c53b78fdd2ff48bc85fa9b1ffaeb660c"
     ]
    },
    "id": "7cOam-83bEXw",
    "outputId": "a71112b0-cd31-4047-f525-648d446cec5f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ff6acec96154856932ca0984b478e23",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7540828b4a1d496a93ca4e5730d643d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c074d2a0cbca46119d90ba098715c9be",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== QUESTION #5 ==========\n",
      "Every day, Wendi feeds each of her chickens three cups of mixed chicken feed, containing seeds, mealworms and vegetables to help keep them healthy.  She gives the chickens their feed in three separate meals. In the morning, she gives her flock of chickens 15 cups of feed.  In the afternoon, she gives her chickens another 25 cups of feed.  How many cups of feed does she need to give her chickens in the final meal of the day if the size of Wendi's flock is 20 chickens?\n",
      "\n",
      "Gold : 20\n",
      "Pred : NO_ANSWER ❌\n",
      "\n",
      "No <answer> tag produced. Last-level thoughts:\n",
      "  • 15 + 25 = 40 cups given in the morning and afternoon. Each chicken gets 3 cups, and there are 20 chickens, so 40 / 3 = 13.333, which means 13.333 * \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5aa9fbb4f5ec4cb880a2ee13aab7483a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce2a49279a7341deb0f20d5493782653",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ec528f60c5d142359a9e58301bba3535",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "========== QUESTION #6 ==========\n",
      "Kylar went to the store to buy glasses for his new apartment. One glass costs $5, but every second glass costs only 60% of the price. Kylar wants to buy 16 glasses. How much does he need to pay for them?\n",
      "\n",
      "Gold : 64\n",
      "Pred : NO_ANSWER ❌\n",
      "\n",
      "No <answer> tag produced. Last-level thoughts:\n",
      "  • 16 glasses would be 8 pairs of glasses, with the second glass in each pair being 60% of $5. So the cost for each pair would be $5 + $5 * 0.6 = $8. The total cost would be 8 pairs * $8\n",
      "CPU times: user 13.1 s, sys: 49.2 ms, total: 13.2 s\n",
      "Wall time: 16.5 s\n"
     ]
    }
   ],
   "source": [
    "# ToT DEBUG for 5-th and 6-th GSM8K test questions\n",
    "%%time\n",
    "import time, re, string, collections\n",
    "from datasets import load_dataset\n",
    "from vllm import SamplingParams\n",
    "\n",
    "# helper functions (reuse)\n",
    "def first_int(t): m=re.search(r\"-?\\d+\", t); return int(m.group()) if m else None\n",
    "_tbl = str.maketrans(\"\", \"\", string.punctuation)\n",
    "norm  = lambda t: t.lower().translate(_tbl).strip()\n",
    "def judge(g, p):\n",
    "    g1, p1 = first_int(g), first_int(p)\n",
    "    return (g1 is not None and g1 == p1) or norm(g) in norm(p)\n",
    "def majority(ans):\n",
    "    nums = [first_int(a) for a in ans]\n",
    "    if all(n is not None for n in nums):\n",
    "        return collections.Counter(nums).most_common(1)[0][0]\n",
    "    return collections.Counter([norm(a) for a in ans]).most_common(1)[0][0]\n",
    "\n",
    "# ToT parameters\n",
    "DEPTH, K, TH_TOK, TEMP = 3, 3, 60, 0.7\n",
    "BASE_SYS = \"\"\"You are a careful problem-solving assistant.\n",
    "Grow a tree of thoughts – one thought per line.\n",
    "When you have the solution, wrap ONLY the final answer in:\n",
    "<answer>\n",
    "...\n",
    "</answer>\"\"\"\n",
    "THOUGHT_MARK = \"Thought: \"\n",
    "\n",
    "def build_prompt(q, thoughts):\n",
    "    msgs = [\n",
    "        {\"role\": \"system\", \"content\": BASE_SYS},\n",
    "        {\"role\": \"user\",   \"content\": q},\n",
    "    ]\n",
    "    for th in thoughts:\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": th})\n",
    "    return tokenizer.apply_chat_template(\n",
    "        msgs, tokenize=False, add_generation_prompt=True\n",
    "    ) + THOUGHT_MARK\n",
    "\n",
    "sampling = SamplingParams(temperature=TEMP, top_p=0.95, max_tokens=TH_TOK)\n",
    "\n",
    "# load slice & LoRA\n",
    "ds_slice = load_dataset(\"openai/gsm8k\", \"main\", split=\"test[4:6]\")\n",
    "lora_handle = globals().get(\"lora_handle\") or model.load_lora(\"grpo_saved_lora\")\n",
    "\n",
    "# run\n",
    "for idx, ex in enumerate(ds_slice, start=5):          # labels 5 & 6 for clarity\n",
    "    q    = ex[\"question\"]\n",
    "    gold = ex[\"answer\"].split(\"####\")[1].strip()\n",
    "\n",
    "    open_nodes, terminals = [([], 0)], []\n",
    "    for d in range(DEPTH):\n",
    "        next_nodes = []\n",
    "        for path, _ in open_nodes:\n",
    "            prompt = build_prompt(q, path)\n",
    "            outs   = model.fast_generate(\n",
    "                prompt, sampling_params=sampling, lora_request=lora_handle\n",
    "            )\n",
    "            texts  = [o.text for o in outs[0].outputs]\n",
    "            for txt in texts[:K]:\n",
    "                thought = txt.split(\"\\n\", 1)[0]\n",
    "                m = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", txt, re.S)\n",
    "                if m:\n",
    "                    terminals.append(m.group(1).strip())\n",
    "                else:\n",
    "                    next_nodes.append((path + [thought], d + 1))\n",
    "        open_nodes = next_nodes[:K]\n",
    "        if terminals:\n",
    "            break\n",
    "\n",
    "    pred = majority(terminals) if terminals else \"NO_ANSWER\"\n",
    "    ok   = judge(gold, str(pred))\n",
    "    print(f\"\\n========== QUESTION #{idx} ==========\")\n",
    "    print(q)\n",
    "    print(\"\\nGold :\", gold)\n",
    "    print(\"Pred :\", pred, \"✅\" if ok else \"❌\")\n",
    "\n",
    "    if not terminals:\n",
    "        print(\"\\nNo <answer> tag produced. Last-level thoughts:\")\n",
    "        for p, _ in open_nodes:\n",
    "            print(\"  •\", p[-1])\n",
    "    else:\n",
    "        print(\"\\nAll terminal answers:\")\n",
    "        for t in terminals:\n",
    "            print(\"  <answer>\", t, \"</answer>\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 893,
     "referenced_widgets": [
      "ef6dc65c9b004c20a167ac291268c4fd",
      "35f53f8f54f24c93b6e32d8716d4a76d",
      "d3159463f3fd4507a0667d14e13c82de",
      "b50e91056463421190568ac93a64d87f",
      "309ca6bd8f53489d9875463bf0c9f4f7",
      "c8d90e1984ca433f95ad7bb56fa91495",
      "003d1f2c8ef04bdcb102797747a48578",
      "7047eb2d1a5a4b2e9615e62f70de2e26",
      "265f23f7dad441fe9f0d1bde9f284927",
      "d3efca2eaf6643299393f73ffdee52c1",
      "cda0a3a95b97403c9c0de6a054fb2703",
      "b258746121424cc39924a2d98b1dbaf5",
      "3e4b523884fc4d639043e896f8244300",
      "66c2664cbeeb445bb01736ff7b063287",
      "1da1cafb29ec4c2da5e3db449aba857a",
      "05b281e3a20047f1b39ed982dabd1f75",
      "4e3e4e1a15784e27b3a226e267803b0a",
      "de08734f317b491bb790c456a39fdca6",
      "bb144b8343874f45a55d8884a95cf35f",
      "704904e2c9d84e7aae7f506e3d2235f0",
      "a805175c4e9340fd9c80f9717ebd0658",
      "4dcc22d424e346539e85078f669ee6a4",
      "50fcc3755a114e989006e8f4dee9bc1a",
      "f94deef2608047b8aa1f9916c4d2861e",
      "839ea8943d624375a2bbe647d7342692",
      "5323b0aa01474050b4796d73fecf8256",
      "101e47c1d39a49769155cc143912c7bf",
      "2d3307e24eee4822a06e79a64318d5f2",
      "9aea1bab2d2c4e3bba671945989d03a7",
      "e27254b7b36049f58376f9a9eb25855a",
      "9a5cf64a11854a5abfa0b7f49bf25f33",
      "90df7b232ecd4e5281c9aeadb2cd98a5",
      "570d533a6cb445c68ace865a6f8bb5f2",
      "4f7e20936f944aa1b2445e5255a3e81d",
      "5a6c70f77902462f87b7c20494feb127",
      "f6be48d0ad3c4f97b73c40a242036f6b",
      "ee881acd9d6d408f867b4170b00a6c47",
      "07e5a68bc58b406598a6e19147fd2214",
      "ca035b57aa7447878eea44600aa8871e",
      "78fb0001446e449388a7dc5237af2063",
      "478cacfe967a4448a54ace44bed28809",
      "9389f191d5ff430eb02b4b023617f806",
      "77855734cb234a5bbf9a9a3837506331",
      "388da4ef8f5348d283158a7d4ddd2999",
      "18b4d87e65464cc1a6f00ba836dd4c1a",
      "f6ace855a71c43ca95e923835e5e1547",
      "0e567f1aada7477badf07c19e29b2190",
      "5f9eafd52a414530bb2e3da1b5b606a0",
      "ea087b870dc8460193eee600860c6b3e",
      "444146df861e4862b037cbe4c9581159",
      "86f0f3fe0d4e4e2d92ac57399266477f",
      "66d318357fd2404c90cfc1665753c5e0",
      "287a29b508b2437fbe5060cf10fc06ff",
      "e9e9fed4015242f08c1d551c8bfdaa26",
      "addae738a4a64943a405fa88722d1dc2",
      "9d76a699df69450f89425f9af25874f7",
      "2541898ee33e486daf2c9b3655ed6436",
      "3e38cc99a97249898904f4d2a7a5553e",
      "b021f5684e334cd99f30d455a596f486",
      "fff1248fbfd34c99b474667945b5e408",
      "29d43c35bfb749df9742cc7dacba3c26",
      "41ac0ce2149e449da4cc442babdafe2a",
      "a908bc214c5844b19358ee1b63eab269",
      "4d4bdc711bef483c87a66d1f2a1aef05",
      "7ac9e12e3a1740ff8c80a8a13c370b95",
      "32837e1ee30f47768aeafa61cdff2945",
      "98fc255ffcef481190fd939bfbfbe724",
      "a365cc141cc64b988b50789155857faf",
      "14c6dc81cf1e4074af4750c894f3f49c",
      "46f5975c3fe446cfa2e8f7141b68d709",
      "e90ec350c16d4298bc34ccb529515088",
      "8473e1c106094f30a0ade4cb1a246841",
      "8fc5d72ab3904678952f2179550676e1",
      "76fe7800155e4a2db64ac15353c6614c",
      "815b4b4f36454884be83c08000874ca9",
      "0f5d81fd7d0d44b893a7b149efbaf177",
      "2d1e8ae89eea465a8a32cf1e271d3d92",
      "abb9158d7fd54b77a05492d48f1fa104",
      "214a4f5b4e8d48b4ab2f41f3b76499dd",
      "b083084195e54eea809fa9564c7ad39f",
      "b5d5265c587c4aa4b0c59d7f52973206",
      "7ad766d54dcc413792409214b39c1060",
      "d84b81da5cae48ee8e0e67d5dc0b3ada",
      "c985c213d8b34dc0b55d6c67193802f1",
      "7f85b8708bd14dd4bca0fa025c3327a9",
      "20c5e1ab4f834a8a8aa93cfc0a7a4e21",
      "b8e1891bf25e4ceea2d6fed3e99b6fa4",
      "b4fd281704854ab6b9d6877962bf865e",
      "b2071ba966d947638e71eb3e8cf4fc11",
      "8c992e1a88ac4d298d43b3236d81bf67",
      "40f4c1f84e8049cfa15a7982af19392a",
      "b49e1953f679425b81278743067e9c83",
      "a0edabbaeae34494aeef0a1c3d3684c5",
      "c0ce328e89c642fc90d8b87d740493fb",
      "efd7e41938e64ba28069a2e7aab15c2a",
      "c37e693c7b2e4da6b4e9c829fc17336b",
      "d8445b9bb45243bab9339bdf89dbd5d2",
      "3541b991d0a2464ba66b7acf92da7204",
      "67f9bb17d8b945bbadddc573845c4164",
      "5999f30a237f4f82ad6a940b58d213f9",
      "0fbface2977d479e9f32f07dee83b780",
      "a31495b7d6394c538ccb6c6f48e6ef2e",
      "db6c99427bb44d3ab1e2a9e3f0128d68",
      "d75a5e29128b483c96ab0df8b236eadc",
      "7400c4c350a74b63b8a949da74f971f1",
      "98575ce358fa467ab929f5a2a4d3d348",
      "917000d2095b4fa0a3bc1776e372b1f2",
      "43a572fc1036475ca752bace07e11df4",
      "f269b8f308f94317a02d9a7e735cf569",
      "8b3873bcd1044cb0905c6560da919fc8",
      "f54b18f1d906460fa21c31175ef84c2f",
      "3c26a7fa60874dcdab2c196a1a82eb8a",
      "1f3613ec94b149beb48b4cce3e0b421e",
      "a2088e52a98e45a7b67e45a3da218bed",
      "44ad72b690244ba5842581043d2ad4e6",
      "d507fedbf8b640dcabaa97d22bf5a55a",
      "6179e91ef3534f7c8f388cce139d7611",
      "c23baa2dcf7048cd98e55da01b1b738d",
      "3ae91d9852814bf49f00674338e2d9eb",
      "134cc5dad0f143fcbb8b45476bc93612",
      "12a375e2800b4842a217a4391e7d8ca1",
      "6485cf480781475c801908f2731aa7a5",
      "dedfcb3169564e89a1df9dba74e5900c",
      "3cf21c331675406fb2c97c6f2d74e6c8",
      "bab155859e2d4356980b5dffcd59780a",
      "332c07dab3314d6f93cc21905238d8c4",
      "cc08b49a3aa5490b8f65022a8ed567a7",
      "14420017fa034e59805d94c3d9145ea2",
      "e4b25a89582a4728af7f626e05bffe73",
      "840ee11e3fdd4872bbf68739e3e32b23",
      "73ac7addbd9343d2b77aaa7272c947a4",
      "34223bc78a3a4a54a47198996f6dd29e",
      "f5baefd949e04d798ae440682562acb9",
      "fe35abfe9991435097f020463a30ad85",
      "400083ec2e0440d9ac5806a5f575c6e6",
      "8a176d150414498b9ad7a3fc08cf3ce8",
      "6e9edf901ca14437abc6320f5946ead1",
      "9abf15a451a84adcab2ee01c952fe109",
      "98a3aec867164aa1886df2c25cd2f1b2",
      "4ebab53ed86f4fbe96b89a79142b965f",
      "e81de149d63b48d0ba3b3371315bfa71",
      "730fc5df41654e32ba5b425c74d83c0a",
      "68aa453ae9ef415ba119cec3c8c98427",
      "eaaf821b94114d88bca2b665a5f17865",
      "4f970c9f83a64bb09644e996f5673d75",
      "341e9d595c304d14a328ac7442dc1813",
      "b49a721716124e1e8f7d4dc667beb886",
      "e8bb3d53650f4dfbb4e96eb6e12daf5c",
      "9078000475ca41f48d9aacde841b58cf",
      "166c40ec519b44f2a48d682d2067de81",
      "890ee606354a407388f3efbaac975c9a",
      "240d7933120145ca821e3135bb9f09be",
      "3a79b5e1b84345eaa4fc4ba91b17941d",
      "59be338f90f244a19a107ef2ab16dbf9",
      "bbfe30cff2d34bfba315fad6053ccfa2",
      "57e58b3a47114656a288788f23fbb911",
      "3cfd4115fb864235817b86a10fae908d",
      "930df4ecdb904c668c1de38cff5dfc55",
      "7915c1259a83433a8df3b012e05a4966",
      "a1758399458340de8906074322731b21",
      "21c806600460456f812fc38c6a77eb93",
      "d7254d50c5504e99a88f832747f27a10",
      "edfdc327fda84523ba928ffca0852006",
      "44d2b8e68ca7401c8974f38fd6099c34",
      "368e75840de347d2bbf96fa785c2e8ca",
      "97fbe41521f04b14abc76aab595a3b95",
      "7ce9d5a7ce294f059b5a9349af2bc9bf",
      "1bee13d3d7cc4d6899d2d9cc9d4cbc64",
      "f7b6f53dc11f4088a721b69e08f767ee",
      "6b93e49a9d694ce081f9db475420888e",
      "0b479c2f1e8a4e3ea3746f48add6636c",
      "f5c91477ee474c839ccb2fd2b672a98b",
      "5080cd0e4ae149df8afbd31663f6ee8d",
      "bfb83d1ae2ba4a51a7dfdcacc87ee496",
      "c5669414155c41a9aa30c11f79fc0491",
      "3a119c653fdc49b1b4e788e53f7fd24a",
      "8b3454ddbdda492aa6fe292ab661ec59",
      "50ec7f73d15846e69c2d3f777c8c499c",
      "1bfd769fd1fe4adba6a1729c8d913222",
      "326a167a99c44668a2ad234e42710b99",
      "e19275c722594b5e8977ec26229e1688",
      "51a17fa79fe449d5a0a88c091f574db7",
      "cc3a928f853c4e42b3f5549a713299ae",
      "3672cafe975d437091c289b17518be92",
      "c1106317735a49f89cc7c3adb2e34e10",
      "550cb7ce34604f4abc29b6d7a9dceb3e",
      "8546d003d2b5438c8d9b584f39261e5c",
      "96cf776db85e41e899989d6f9d70ac47",
      "8683014a2e294c1bbc39d7a2a58a9e1a",
      "8860a7e85fd4476e9c2a80087615bb9d",
      "aac7a675365548e19a2c937e81ff560d",
      "2cbb190ce54249bf9674fb0200f73f4d",
      "792faeccbedd4d46adccdaccbc3a4c5f",
      "4bc00e72a925401da338ac9f676c6659",
      "ca6ad98f2ca24a4f890bbb866855e7a4",
      "f6229a863c8a4c0eb656b60bfbe7a911",
      "bf6cacc36b1a48aebf3861e1025ad71e",
      "6270da26d08741959ed03295002fb4ad",
      "3e6cad0193f84c96986e9b800fa53c75",
      "0ca15504ccbe4996be3db069f86cf1bb",
      "21fd055bc74645a29a0b438c343f5c05",
      "5468c6355b9e496ca3508fc47596786b",
      "9019f94594af43f7a048ad1eb280a36f",
      "b316941d5e2e49e4bb7f6b4cf71b26a3",
      "ab0dd39cb3fd49c983ddd7d357bb95f3",
      "ddebb8dcb57446918225918e5e6150eb",
      "e34a4ce23208471da4148f8bc578dfe3",
      "0479559ab6944602aa1df26f410db0c9",
      "e5bfc9edb49a4590a34c37f51bec78d1"
     ]
    },
    "id": "WNHUMC5Wbm5o",
    "outputId": "80d790b8-6138-43b7-b455-bb22aa5791ce"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef6dc65c9b004c20a167ac291268c4fd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating 10 examples:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b258746121424cc39924a2d98b1dbaf5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] gold=    18  pred=correctnumber  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50fcc3755a114e989006e8f4dee9bc1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] gold=     3  pred=correctnumber  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f7e20936f944aa1b2445e5255a3e81d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "18b4d87e65464cc1a6f00ba836dd4c1a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9d76a699df69450f89425f9af25874f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "98fc255ffcef481190fd939bfbfbe724",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] gold= 70000  pred=   70000  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "abb9158d7fd54b77a05492d48f1fa104",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] gold=   540  pred=correctnumber  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b2071ba966d947638e71eb3e8cf4fc11",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5999f30a237f4f82ad6a940b58d213f9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] gold=    20  pred=      20  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f54b18f1d906460fa21c31175ef84c2f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] gold=    64  pred=correctnumber  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6485cf480781475c801908f2731aa7a5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5baefd949e04d798ae440682562acb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eaaf821b94114d88bca2b665a5f17865",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bbfe30cff2d34bfba315fad6053ccfa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] gold=   260  pred=       4  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "97fbe41521f04b14abc76aab595a3b95",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b3454ddbdda492aa6fe292ab661ec59",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/10] gold=   160  pred=     120  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "96cf776db85e41e899989d6f9d70ac47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] gold=    45  pred=     120  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e6cad0193f84c96986e9b800fa53c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] gold=   460  pred=correctnumber  ❌\n",
      "\n",
      "Accuracy on 10 examples: 20.00%\n",
      "Mean latency per expansion: 3.12 s\n",
      "CPU times: user 55.8 s, sys: 213 ms, total: 56.1 s\n",
      "Wall time: 59.2 s\n"
     ]
    }
   ],
   "source": [
    "# Tree-of-Thought (depth-4, answer-biased beam) on 10 GSM8K\n",
    "%%time\n",
    "import time, re, string, collections, math\n",
    "from datasets import load_dataset\n",
    "from tqdm.auto import tqdm\n",
    "from vllm import SamplingParams\n",
    "\n",
    "# helpers\n",
    "def first_int(t):\n",
    "    m = re.search(r\"-?\\d+\", t)\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "_tbl = str.maketrans(\"\", \"\", string.punctuation)\n",
    "norm  = lambda t: t.lower().translate(_tbl).strip()\n",
    "\n",
    "def judge(gold, pred):\n",
    "    g1, p1 = first_int(gold), first_int(pred)\n",
    "    return (g1 is not None and g1 == p1) or norm(gold) in norm(pred)\n",
    "\n",
    "def majority(ans):\n",
    "    nums = [first_int(a) for a in ans]\n",
    "    if all(n is not None for n in nums):\n",
    "        return collections.Counter(nums).most_common(1)[0][0]\n",
    "    return collections.Counter([norm(a) for a in ans]).most_common(1)[0][0]\n",
    "\n",
    "# search configuration\n",
    "DEPTH           = 4           # more search levels\n",
    "K               = 3           # beam width\n",
    "THOUGHT_TOKENS  = 100         # more tokens per thought\n",
    "TEMP            = 0.7\n",
    "\n",
    "BASE_SYS = \"\"\"You are a careful problem-solving assistant.\n",
    "Grow a tree of thoughts – one thought per line.\n",
    "IMPORTANT: You have at most FOUR thoughts. The final line MUST be:\n",
    "<answer>correct_number</answer>\"\"\"\n",
    "\n",
    "THOUGHT_MARK = \"Thought: \"\n",
    "\n",
    "def build_prompt(q, thoughts):\n",
    "    \"\"\"Return full prompt string with an assistant prefix ready for next thought.\"\"\"\n",
    "    msgs = [\n",
    "        {\"role\": \"system\", \"content\": BASE_SYS},\n",
    "        {\"role\": \"user\",   \"content\": q},\n",
    "    ]\n",
    "    for th in thoughts:\n",
    "        msgs.append({\"role\": \"assistant\", \"content\": th})\n",
    "    prompt = tokenizer.apply_chat_template(\n",
    "        msgs,\n",
    "        tokenize=False,\n",
    "        add_generation_prompt=True        # <-- ensures assistant tag\n",
    "    )\n",
    "    return prompt + THOUGHT_MARK\n",
    "\n",
    "sampling = SamplingParams(\n",
    "    temperature = TEMP,\n",
    "    top_p       = 0.95,\n",
    "    max_tokens  = THOUGHT_TOKENS,\n",
    ")\n",
    "\n",
    "# load LoRA once\n",
    "lora_handle = globals().get(\"lora_handle\") or model.load_lora(\"grpo_saved_lora\")\n",
    "\n",
    "# dataset slice\n",
    "ds = load_dataset(\"openai/gsm8k\", \"main\", split=\"test[:10]\")\n",
    "\n",
    "acc, latencies = 0, []\n",
    "for idx, ex in enumerate(tqdm(ds, desc=\"Evaluating 10 examples\"), 1):\n",
    "    q    = ex[\"question\"]\n",
    "    gold = ex[\"answer\"].split(\"####\")[1].strip()\n",
    "\n",
    "    open_nodes  = [([] , 0)]     # (thought_path, depth)\n",
    "    terminals   = []\n",
    "\n",
    "    for d in range(DEPTH):\n",
    "        next_nodes = []\n",
    "\n",
    "        for path, _ in open_nodes:\n",
    "            prompt = build_prompt(q, path)\n",
    "            t0 = time.perf_counter()\n",
    "            outs = model.fast_generate(\n",
    "                prompt,\n",
    "                sampling_params = sampling,\n",
    "                lora_request    = lora_handle,\n",
    "            )\n",
    "            latencies.append(time.perf_counter() - t0)\n",
    "\n",
    "            texts = [o.text for o in outs[0].outputs]\n",
    "            for txt in texts[:K]:\n",
    "                first_line = txt.split(\"\\n\", 1)[0]\n",
    "                new_path   = path + [first_line]\n",
    "\n",
    "                m = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", txt, re.S)\n",
    "                if m:\n",
    "                    terminals.append(m.group(1).strip())\n",
    "                else:\n",
    "                    next_nodes.append((new_path, d+1))\n",
    "\n",
    "        # keep any finished branches plus top-K unfinished ones\n",
    "        open_nodes = next_nodes[:K]\n",
    "\n",
    "        if terminals:            # early stop – found at least one answer\n",
    "            break\n",
    "\n",
    "    # decide prediction\n",
    "    if terminals:\n",
    "        pred = majority(terminals)\n",
    "    else:\n",
    "        # fallback: take the first int from the last surviving thought path\n",
    "        fallback = first_int(open_nodes[0][0][-1]) if open_nodes else None\n",
    "        pred = str(fallback) if fallback is not None else \"NO_ANSWER\"\n",
    "\n",
    "    correct = judge(gold, str(pred))\n",
    "    acc    += correct\n",
    "\n",
    "    flag = \"✅\" if correct else \"❌\"\n",
    "    print(f\"[{idx}/10] gold={gold:>6}  pred={str(pred):>8}  {flag}\")\n",
    "\n",
    "# summary\n",
    "print(f\"\\nAccuracy on 10 examples: {acc/10:.2%}\")\n",
    "print(f\"Mean latency per expansion: {sum(latencies)/len(latencies):.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 861,
     "referenced_widgets": [
      "5a223858268f44edb59a1cc65980b518",
      "1255e6b3977e43b8baf14376e19a7e36",
      "eb300113b0c543d195dcfdb8670df959",
      "5a427ce0dabd4c4b944230aa74a3f113",
      "a785487d456f49db822dc4b8b1b14669",
      "8c4fb4d4052c49079fc5476a9d1b6bb2",
      "2965090b31644ad3a7e24f15bdea06ae",
      "a9827a9cb2ce46908adeff074bf19dfe",
      "276de77e7fe44346a59d3aee698bb7f1",
      "8f4fec53d2344ce8aa8d027ba580394d",
      "66edffd496ef4100a2638dbbb3ee7b06",
      "29ee3a097aa848c1be72bbd57a1e576e",
      "28ee43af743d438d9eb73af72178ef80",
      "157f7e497ee34bc09165b7db1c56ec32",
      "99b9d643c4d040dbbeb7ea55f3cf4165",
      "94e1a2bf11b2462fbabcd6fad8f7c7b1",
      "004eab818ed84e048ecc3dfcfc730d01",
      "392a011a973649a1b9e82df476edd261",
      "7a1041f8fa58477ba0a02f055802dc09",
      "570090566a714659be54223e5c737d80",
      "b36b33f64d1e4d1886073c8028731ee0",
      "adf0f65a787b43dc8fb2d6e4d2b796b5",
      "04fd96d9ba69449a956a7ce390904622",
      "8fe4f60a79d64a9ab8afd1ace91f982f",
      "b3290c269d5045e485c22c35d4956cd9",
      "c724cc0c0d4b45498eb3073a94f57693",
      "aa7df1bf905e4ef8a0c869a4ace749e7",
      "4f237e1854dc459aaac78f3f518ad116",
      "5fca2a12634941a992287ae5287a7b59",
      "a1777d39cf9f4588a4d0faf3c13345fc",
      "1fca8f0d8a5f43839046376921dbec28",
      "d6ef3d71996e4cd19597c6c6a073d866",
      "78a0d5903a5f410ba8e6de06a0064e38",
      "a5e78a1d42244b4fa11e26000e2d1189",
      "4c29ca34b0864ed2a759ca74582d6824",
      "6642b30a1a5048e08bed44b6f360632c",
      "a216070fb0b84075b8b659c068a14698",
      "420ac330461f4f9886b09d32410dc18b",
      "32263a7b0df14fe5ae7d30b8148999b0",
      "409a40248b414bb2be5fdfd9bb3eb9d3",
      "d352d9da2769457f8c2f2b53f2eb9a99",
      "52ff1fc12139413ca3a83d056288d75d",
      "46c972f6d979470faf0d1c5cdb163577",
      "671c70fd695445939247890474976ad6",
      "12ce617d313646f5b0c94adbb90592b7",
      "4ce16772fdd5414495a8f5d1dd3a747d",
      "abdf72ba9cbf41fab339b1f34c625fc1",
      "9295001ddc844d7eb697b0f5858db76d",
      "d85f1dccfb364b93b8a7e813c904da1f",
      "461e5e7824bc4499a34f3b3bb8d9a84b",
      "aa2cba0a9e734eb2a788897fdbf9420f",
      "a9fdb7c18a98452d983dfe09ad46fa5f",
      "90922e3a68ff4a849e12fd7c9b74f2fc",
      "0e76d65a8c4043efaba382c49bf1f37a",
      "f5798851f6344549b5f4fa5511de2165",
      "a29bf8e2faca452cae0a045c8a117469",
      "3ba18cb5860a4215b0cd4e635d4db8f7",
      "05513ff9fb5c4ae0b47149993cafa813",
      "16d0c84dfaa143f0a771824db27ab26e",
      "cb2147deb34f4075988b630f090de002",
      "e6454e52ba0443ad8d222e5e4e7a8241",
      "c2b5a7deeb65460194710aa28d552c9d",
      "cdbb72d9cda34c839cffa24fe7ef9b1b",
      "169cb5b1ca254c73893ed7262b21d5f0",
      "ad3ab00e953d4264a9bf863f15b91687",
      "6e96e7ca33654ce2b1e8d80dd3d29efe",
      "1ca62bdbc9c14cb38ece07410a832589",
      "338a188349214cb48f240efc43ac9484",
      "595a26deaf71482b9c17ce452faaf512",
      "2de9d0c7fb59473996c27ccbe26a0553",
      "f59af2185db446bf95634be711931596",
      "747a88cdc8444ba392fc2ed4759295ed",
      "3804a1f6c7464698ae1779c94646efcd",
      "c9067e08167c4a4fad1542e064ea8df4",
      "6cf67afc12304e74837b170a91d34bb4",
      "2257522a83104f7c835a7a7b4e88d917",
      "91548b61a2354742a46a80e335aa2200",
      "b18e1050a7f8433098c6b618e2a5542a",
      "c1893463765b40b1a732733232ed4952",
      "4362bc91111b48718c4d336ca12341a8",
      "4006a51ee96c4883a5f8e0ecbe65eb55",
      "03a08f5b40c049dbb20fc8bc5603f089",
      "f89db771b4c949a0b78651bb85ac6e7b",
      "ea59f1bba5fa444c900ada6c2cbf56ee",
      "57c6b8c67d044a7bba71ad84a761108f",
      "4d81cd6c85804bcab6c2fa91b4b7598d",
      "93c2b62b9fd442f69f6213b1e18295bf",
      "8cdf4df58ba547f3b9cf7a938fb9ad08",
      "1c2e209ab7014f0b8f5201848b8ebf78",
      "2a2778bffc70407bbc3c9857fe5fb9ec",
      "ce0961a36b244c0892f9d840fce8f4fc",
      "a9647c9f2aa24494aeebb9bbd10a603b",
      "84442dc2a9764c70a89b214ca05fa767",
      "bd867d99f7b541f38731191bb5f3c1e4",
      "da8fcf9611c7476fbe2c5e7f7b2fa091",
      "9cfa5433d78f4362b844dcb87c03ea44",
      "e89025e51d4d431cb2a440732776c9e0",
      "9e8d563ff32f4529aa26228a36de7281",
      "99a270ed4855481c875ae2fcc98947f9",
      "30eda7b562034668873a1bd711d7d9b2",
      "435bd3637c3b407b9820bae429c6b64e",
      "9696a9341c924ffd9bde5ecc994fdf15",
      "d174c9f302dc4952be78bc47e8bb3ce2",
      "4bc9f00e981a4d7b8052073cd10ee3d6",
      "b57948f9de7049269159858899720b31",
      "fbaae780ce2d41199727bce4253c849e",
      "4cfe23e2d99943f8b088765557d1374a",
      "9189c5ade3b247d98df4446a80cee00e",
      "f956a4f695be44cab835faa47f05a43a",
      "98916a32b6af4ba987a05183451b4ffc",
      "906ab078af174a0f9ce06f1c86a455fc",
      "6c2ae6bd48c0406aad5d3ac3bb941bf1",
      "1e897e72a0564d5a8fd1fb90f84a7504",
      "6d2ba19e7b2b4ed9b5c84bf13ea35ebb",
      "e66d1ae185e8463c8d3a0a2d62e3deb5",
      "c6562abd01524637ad0d433864a54d4b",
      "d31622c4a9cf407d91b3f544da8474f3",
      "561635af13f240a7ab0c2ccf6475397c",
      "276cca790e8e47a2bfaad80fdbfd8365",
      "9021e529a4f442b0be61557eab72e35f",
      "032a86ae3b3547ef9b1d3dff6334494d",
      "62da38b648734d7e8d8cdb2833eb5c64",
      "e6652cca30e5477caff1345128ec2844",
      "93369697ef2a40cf9fa77e5d6db623c8",
      "0a1b98a9c9ef4ade9f6dcca88441ef48",
      "dec3e0c0734446b094c317bf7efa0017",
      "a5f6551ba0904b118b85b0cc131c5bcd",
      "1d49466768c24d0bb454f9200125e31c",
      "ba0d5103f2df48709b5b6e385bcb9290",
      "8a7641a439e2407a80ff8d87f37c21a5",
      "f0d3aeece20b46bda2b8855a52689dfc",
      "234618b2e0a74d6eb1848da99b7b8775",
      "ca3a675de06f4584813113bbd81ba15a",
      "04fd921f39e54adba559201d102e1ea9",
      "262128515ec1464089d1310b66e47a6a",
      "28c05809d3694688a9c21b11a6b75842",
      "a2de67e4214649618081bacf5b77f241",
      "33e906869b2a4ccaa9f410c061b7b9ff",
      "127f0be4ece74631a14f6a1e615f67ce",
      "b93a89f96e9c4e89a8e8a889139357b3",
      "7941a085deaf4be0bf4e20a4f0d8096d",
      "f72d6677daf94a63bdd9e688b92edec6",
      "17083786f6194846b2a1306c7f24c63e",
      "2b67e669a6954ae6b4ec4a07ab5cad6f",
      "e332b224a9a6435bbb781e44baa373ec",
      "92cd00ccd15a40f486a30f39191beaa2",
      "d99dd2806cde4e0883c2a9309b1527bc",
      "44a50e33a04a4064b21d21bb0f0f29d8",
      "af14f2a6405e48e4b77d4c2939119b79",
      "dd6677cf5e604c5a9176286ac20c7719",
      "2e321fe7cd094384ad077bea54f1704e",
      "3b75466334254ee080d4e7456f3b8d4a",
      "fc71ac8941f34bc2b157864b319ca91a",
      "47cfc4a055a1443ba8652c0aeadde227",
      "ead08577c0f947ac97f56dea434adb86",
      "2ee2059479b9404ba62214192fc44ce5",
      "51025b155f384a7ebf0b06070941c2c4",
      "d45baf4f01414c21966ae2cdcab0cacf",
      "b07ddc3cdf9e4fc29fa193e36bcc1a6d",
      "7135d6fd50cf4bec8eba574058f44db2",
      "d7c9e186bb954e6b9e571b213f1a2770",
      "35672df4b8aa4f6c88b3e0c1588f230b",
      "9cbec626a7cf40179c46afecad54ed87",
      "d499293431994d2684ffda8114ad6c03",
      "00cd9632c881493a8bcb7a9575bdcd51",
      "df66e08ff4a2469ab8b3c6195dc8a37e",
      "72a9700ad328424882d1e2976fbc1cf9",
      "c7528b4475e44a5ab9d39ce350a8781e",
      "df76c627a5204d9ea3814be0e78ba000",
      "a9eb88380c7647f6bea090103060cad2",
      "6f35409775b848169ed6e646af29cdcc",
      "31961d6c437e4f759b6b4a373e622881",
      "9294d050beab432993e391fc80532efb",
      "72cba660fe9245b0be6c989366c18e4b",
      "d8961e6089444258adcb19b91302a77a",
      "0fac03e876ba4240aa03840e14ac4b75",
      "e179ac204fcb4260b9a0314990c24a24",
      "cbe80819830d48e4af11735897743087",
      "484725a415b14082a302d8f7b460fc49",
      "b6aafc57f7414e358c15d1ce68a70846",
      "df897b83a5454c9684f01204a41c94ea",
      "cd4613b959c541ffb9268c5c36ec829c",
      "6208fc5853724e21adac33b083445e37",
      "7b8be0b832a34f12967efedd387e81f4",
      "c8354d4a664d4d8ab145c5667d3fa7b8",
      "d0183fade09a427c9fcd0fb4764dd4ac",
      "3786aa15216541d8a897f41e7368a7a5",
      "a58571061db948f19963e50526127763",
      "51453f74c17c45e198994c208f1ed53c",
      "0cb9877058ff4a8eaca5a27363cea914",
      "35edaf1bed154c34981a7afaca5f0757",
      "b8eea35428184c1ca88e1a9c507a8878",
      "52cf7f4d938d494e84332df24eb6cd2a",
      "e2e24b6342b946459dde9e24a5656524",
      "16900a3b76684f4485ceb6a41c3fac31",
      "850b177acd8942cabf705eb40a48131d",
      "b985657e629f456eb3da42408434a0b8",
      "6a1ac04e91c34e8a8adf68549bdebfa4"
     ]
    },
    "id": "bR9V13RXb7kz",
    "outputId": "275ca3b1-331e-49b4-d006-30717df3f34f"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5a223858268f44edb59a1cc65980b518",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "10-example eval:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "29ee3a097aa848c1be72bbd57a1e576e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/10] gold=    18  pred=      18  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "04fd96d9ba69449a956a7ce390904622",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2/10] gold=     3  pred=       3  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a5e78a1d42244b4fa11e26000e2d1189",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "12ce617d313646f5b0c94adbb90592b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a29bf8e2faca452cae0a045c8a117469",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1ca62bdbc9c14cb38ece07410a832589",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3/10] gold= 70000  pred=      42  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b18e1050a7f8433098c6b618e2a5542a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4/10] gold=   540  pred=      42  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1c2e209ab7014f0b8f5201848b8ebf78",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[5/10] gold=    20  pred=      20  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "30eda7b562034668873a1bd711d7d9b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "906ab078af174a0f9ce06f1c86a455fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6/10] gold=    64  pred=      64  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "62da38b648734d7e8d8cdb2833eb5c64",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[7/10] gold=   260  pred=     260  ✅\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca3a675de06f4584813113bbd81ba15a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8/10] gold=   160  pred=     120  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2b67e669a6954ae6b4ec4a07ab5cad6f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ead08577c0f947ac97f56dea434adb86",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "df66e08ff4a2469ab8b3c6195dc8a37e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[9/10] gold=    45  pred=      42  ❌\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e179ac204fcb4260b9a0314990c24a24",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a58571061db948f19963e50526127763",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10/10] gold=   460  pred=     460  ✅\n",
      "\n",
      "Accuracy on 10 examples: 60.0%\n",
      "Mean latency per expansion: 3.24 s\n",
      "CPU times: user 54.7 s, sys: 207 ms, total: 54.9 s\n",
      "Wall time: 57.9 s\n"
     ]
    }
   ],
   "source": [
    "# ToT evaluation on 10 GSM8K (fixed prompt)\n",
    "%%time\n",
    "import time, re, string, collections\n",
    "from datasets import load_dataset\n",
    "from vllm import SamplingParams\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "# utility helpers\n",
    "def first_int(t):\n",
    "    m = re.search(r\"-?\\d+\", t)\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "tbl = str.maketrans(\"\", \"\", string.punctuation)\n",
    "norm = lambda t: t.lower().translate(tbl).strip()\n",
    "\n",
    "def correct(gold, pred):\n",
    "    g, p = first_int(gold), first_int(pred)\n",
    "    return (g is not None and g == p) or norm(gold) in norm(pred)\n",
    "\n",
    "def majority(ans):\n",
    "    nums = [first_int(a) for a in ans]\n",
    "    if all(n is not None for n in nums):\n",
    "        return collections.Counter(nums).most_common(1)[0][0]\n",
    "    return collections.Counter([norm(a) for a in ans]).most_common(1)[0][0]\n",
    "\n",
    "# search parameters\n",
    "DEPTH          = 4          # thought levels\n",
    "K              = 3          # beam width\n",
    "TOKENS         = 120        # tokens per thought\n",
    "TEMP           = 0.3\n",
    "SYS_PROMPT = (\n",
    "    \"You are a careful problem-solving assistant.\\n\"\n",
    "    \"For each question, think step-by-step – one line per thought.\\n\"\n",
    "    \"When you are ready, output one final line EXACTLY in this form:\\n\"\n",
    "    \"<answer>42</answer>\\n\"\n",
    "    \"…replacing 42 with the numeric answer. Do not write anything after </answer>.\"\n",
    ")\n",
    "TH_MARK = \"Thought: \"\n",
    "\n",
    "def prompt_for(question, thoughts):\n",
    "    \"\"\"assemble full text prompt ending with 'Thought: ' ready for generation\"\"\"\n",
    "    msgs = [{\"role\":\"system\",\"content\":SYS_PROMPT},\n",
    "            {\"role\":\"user\",  \"content\":question}]\n",
    "    for t in thoughts:\n",
    "        msgs.append({\"role\":\"assistant\",\"content\":t})\n",
    "    text = tokenizer.apply_chat_template(\n",
    "        msgs, tokenize=False, add_generation_prompt=True\n",
    "    )\n",
    "    return text + TH_MARK\n",
    "\n",
    "params = SamplingParams(\n",
    "    temperature = TEMP,\n",
    "    top_p       = 1.0,\n",
    "    max_tokens  = TOKENS,\n",
    ")\n",
    "\n",
    "# load LoRA once\n",
    "lora_handle = globals().get(\"lora_handle\") or model.load_lora(\"grpo_saved_lora\")\n",
    "\n",
    "# evaluate first 10 test examples\n",
    "ds      = load_dataset(\"openai/gsm8k\", \"main\", split=\"test[:10]\")\n",
    "correct_cnt, lat = 0, []\n",
    "\n",
    "for idx, ex in enumerate(tqdm(ds, desc=\"10-example eval\"), 1):\n",
    "    q, gold = ex[\"question\"], ex[\"answer\"].split(\"####\")[1].strip()\n",
    "    open_nodes, terminals = [([],0)], []\n",
    "\n",
    "    for d in range(DEPTH):\n",
    "        next_nodes = []\n",
    "        for path,_ in open_nodes:\n",
    "            ptxt = prompt_for(q, path)\n",
    "            t0   = time.perf_counter()\n",
    "            outs = model.fast_generate(ptxt, sampling_params=params, lora_request=lora_handle)\n",
    "            lat.append(time.perf_counter() - t0)\n",
    "\n",
    "            for txt in [o.text for o in outs[0].outputs][:K]:\n",
    "                first_line = txt.split(\"\\n\",1)[0]\n",
    "                m = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", txt, re.S)\n",
    "                if m:\n",
    "                    terminals.append(m.group(1).strip())\n",
    "                else:\n",
    "                    next_nodes.append((path+[first_line], d+1))\n",
    "\n",
    "        # keep finished paths; prune unfinished ones to beam K\n",
    "        open_nodes = next_nodes[:K]\n",
    "        if terminals:\n",
    "            break\n",
    "\n",
    "    # choose prediction\n",
    "    if terminals:\n",
    "        pred = majority(terminals)\n",
    "    else:\n",
    "        # fallback only if every surviving thought has a single integer\n",
    "        ints = [first_int(p[-1]) for p,_ in open_nodes]\n",
    "        pred = ints[0] if ints and None not in ints and len(set(ints))==1 else \"NO_ANSWER\"\n",
    "\n",
    "    is_ok = correct(gold, str(pred))\n",
    "    correct_cnt += is_ok\n",
    "    print(f\"[{idx}/10] gold={gold:>6}  pred={str(pred):>8}  {'✅' if is_ok else '❌'}\")\n",
    "\n",
    "# summary\n",
    "print(f\"\\nAccuracy on 10 examples: {correct_cnt/10:.1%}\")\n",
    "print(f\"Mean latency per expansion: {sum(lat)/len(lat):.2f} s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 426,
     "referenced_widgets": [
      "a0e66f17ca4a42e7ad5b149eeaeb193e",
      "867adfc595684af6b09d400f17535806",
      "db56d65c0c03498c9e00dec79c705200",
      "13e976993acf4aedabd01f69f068a473",
      "37f705f0c7bc4bd0a2c19e1868d5cec4",
      "10c89e9600614f90b38214d75a623f20",
      "8531323e42b54abea256feedaa750697",
      "fd778ec8bdee4bcd8a8d156387c4b77a",
      "665a668006184b2f85838da2640fdbf1",
      "5cba519bbe984ec9bcc4fd0ff94aac45",
      "f62474b2d3fc4f24a29d56a29b4c3641"
     ]
    },
    "id": "HLFsncktLNr9",
    "outputId": "ee14d851-1341-4f1b-84df-0713bd85af4b"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a0e66f17ca4a42e7ad5b149eeaeb193e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====== QUESTION ======\n",
      "Josh decides to try flipping a house.  He buys a house for $80,000 and then puts in $50,000 in repairs.  This increased the value of the house by 150%.  How much profit did he make? \n",
      "\n",
      "====== MODEL OUTPUT ======\n",
      "<reasoning>\n",
      "Josh initially spent $50,000 on repairs, making the total cost of the house $80,000 + $50,000 = $130,000. The value of the house increased by 150% from its original value of $80,000. To find the new value, we calculate 150% of $80,000, which is 1.5 * $80,000 = $120,000. Adding this to the original value gives $80,000 + $120,000 = $200,000. The profit is the difference between the new value and the total cost of the house, which is $200,000 - $130,000 = $70,000.\n",
      "\n",
      "</reason \n",
      "\n",
      "====== GOLD ANSWER ======\n",
      "70000\n",
      "====== PREDICTED ANSWER ======\n",
      "<reasoning>\n",
      "Josh initially spent $50,000 on repairs, making the total cost of the house $80,000 + $50,000 = $130,000. The value of the house increased by 150% from its original value of $80,000. To find the new value, we calculate 150% of $80,000, which is 1.5 * $80,000 = $120,000. Adding this to the original value gives $80,000 + $120,000 = $200,000. The profit is the difference between the new value and the total cost of the house, which is $200,000 - $130,000 = $70,000.\n",
      "\n",
      "</reason\n",
      "Correct? True\n",
      "Latency: 7.18 s\n",
      "CPU times: user 7.18 s, sys: 46.4 ms, total: 7.23 s\n",
      "Wall time: 10 s\n"
     ]
    }
   ],
   "source": [
    "# One-example GSM8K sanity check\n",
    "%%time\n",
    "import time, re, string\n",
    "from datasets import load_dataset\n",
    "from vllm import SamplingParams\n",
    "\n",
    "# helpers\n",
    "def first_int(text):\n",
    "    m = re.search(r\"-?\\d+\", text)\n",
    "    return int(m.group()) if m else None\n",
    "\n",
    "_tbl = str.maketrans(\"\", \"\", string.punctuation)\n",
    "def normalise(text):\n",
    "    return text.lower().translate(_tbl).strip()\n",
    "\n",
    "def is_correct(gold, pred):\n",
    "    gnum, pnum = first_int(gold), first_int(pred)\n",
    "    if gnum is not None and gnum == pnum:\n",
    "        return True\n",
    "    return normalise(gold) in normalise(pred)\n",
    "\n",
    "# attach LoRA once\n",
    "lora_handle = model.load_lora(\"grpo_saved_lora\")\n",
    "\n",
    "# fetch one test example\n",
    "test_ds  = load_dataset(\"openai/gsm8k\", \"main\", split=\"test\")\n",
    "ex       = test_ds[2]                       # choose any index\n",
    "question = ex[\"question\"]\n",
    "gold_ans = ex[\"answer\"].split(\"####\")[1].strip()\n",
    "\n",
    "prompt = tokenizer.apply_chat_template(\n",
    "    [{\"role\":\"system\",\"content\":SYSTEM_PROMPT},\n",
    "     {\"role\":\"user\",  \"content\":question}],\n",
    "    tokenize=False,\n",
    "    add_generation_prompt=True,\n",
    ")\n",
    "\n",
    "# deterministic generation\n",
    "sampling = SamplingParams(\n",
    "    temperature = 0.0,      # 0 → greedy / deterministic\n",
    "    top_p       = 1.0,\n",
    "    max_tokens  = 200,\n",
    ")\n",
    "\n",
    "t0 = time.perf_counter()\n",
    "completion = model.fast_generate(\n",
    "    prompt,\n",
    "    sampling_params = sampling,\n",
    "    lora_request    = lora_handle,\n",
    ")[0].outputs[0].text\n",
    "latency = time.perf_counter() - t0\n",
    "\n",
    "# extract <answer> block\n",
    "m = re.search(r\"<answer>\\s*(.*?)\\s*</answer>\", completion, re.S)\n",
    "pred_ans = m.group(1).strip() if m else completion.strip()\n",
    "\n",
    "# results\n",
    "print(\"====== QUESTION ======\")\n",
    "print(question, \"\\n\")\n",
    "print(\"====== MODEL OUTPUT ======\")\n",
    "print(completion, \"\\n\")\n",
    "print(\"====== GOLD ANSWER ======\")\n",
    "print(gold_ans)\n",
    "print(\"====== PREDICTED ANSWER ======\")\n",
    "print(pred_ans)\n",
    "print(f\"Correct? {is_correct(gold_ans, pred_ans)}\")\n",
    "print(f\"Latency: {latency:.2f} s\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000,
     "referenced_widgets": [
      "1d67d617b9b24a458443046a056861bc",
      "57ba5f5332cb4713b4e4a63784206353",
      "c2aecc97582c4d7b86ae8841f42c3206",
      "95a85100c6d64b62b4d3376c97136489",
      "924961ae33a24b8b846167a862ccd0db",
      "300d8c9b0e9d4c9baf2ea20963746dcd",
      "5a5c56b8e3c3447eaaec1ab2d4912102",
      "3c96e0f39c944263b8d0d762207af494",
      "3b075c964cff470caf2102b72f777088",
      "43af33e9a76a4d6b8e3d3d3f299cf4bd",
      "76ad520c28a4421397daa38e97dd6950",
      "7408115f17f746089339c637287b01a4",
      "59c7e013d321469cbc515a8ef26eef18",
      "87c58c4f088547069af840b794a15525",
      "0c1fe3d4c00e434ebe4a4b1b679ab4f8",
      "245df7a3231943db8910fcc7e6cf9403",
      "cdbcc5fa51144f15a6a6e939507a49f5",
      "ba1e5d2ee5ca4375b8d7f14e013c855a",
      "33229001f29f4659a547d5fd5357f974",
      "7c074d2e4f4a4210b2d53ab510b8c7d1",
      "4707b9bab78e43d38d058ca43d9dcf59",
      "518d6420ea554655b80d6873a4df7747",
      "933da30f23ec4b89a8818ffaf01cc1e3",
      "774ff1b489a74c27916800921b3c2d8d",
      "b49d7c33f5b149179b49e9c59618fd3a",
      "4de11dbd5f87477f81db6c8ea89f5b38",
      "c7f91248dae44ab4a56d3ea8729d9571",
      "30cd027f603f45c7af2b51f6bf782c75",
      "025c75e776ff416a9b77f10266939aeb",
      "129301cdbee449549d5bd47f47b5df63",
      "b33c3c58c9094148806c8ef9fed698d6",
      "aeccddcdf42545deb65c5ee92b1fd17f",
      "1e2312494b4748cab151bcf1cd034924",
      "b1b5c8ce0ff84bdba7c9c324acf20d68",
      "f9b3e6639f274ebf9ea1c4ce549afd57",
      "20e998f198354db292d031ec52d3e137",
      "99950661e84346b6901c666a2756f829",
      "a7777ee5c5754a6bae874de29fd7b3e2",
      "e0a70667dbf74919a9aa1fe9cf8eecc5",
      "8495811ad19a4fd99e628a071dd608be",
      "2b547e975f0d4c83844c76a1a0e90a4f",
      "60887057e44e4c02b79daaf598a24863",
      "c56cb6681f954d62a736cf30375e5608",
      "541e3bc157ae404e9318debdb15b9bb7",
      "4e32c0cc336b4c0d83192e16ee512907",
      "32e9b9b6fe00431d89b7cb9339af7846",
      "78c4f47e874b42d383514af784a0c7b8",
      "323caaa664e640b9a4976f0a58c2c58d",
      "eaeefb130b2b4351b4f90ec94c7d1d53",
      "55b9d01e1a1f41ccb3efa4682ed74ded",
      "313998ca69fd40999a5809a8149e46db",
      "a29bb904c8384d3995ba2d811553ada8",
      "b1a92722805141658b51306a15f694cf",
      "9bd10922ca57463899d16ca02cb13154",
      "306c5b45dc3e4e98bdb923e65b72370a",
      "fb33d2751a16416fad5af4aa03c9b780",
      "c2035991d67a4114b2ec9e523fe7421d",
      "4461c0e880d24875aefb99c6b1664aca",
      "8fc146c8cd364abfbba8633e3024be93",
      "90fa40119c6d4765893207c2c8a09c8c",
      "f95970747d2e4ce1a0d57bb5da4b0348",
      "ef50c593b6b741608404f86daab57cd8",
      "f68848b4e1284c3688538716a51262a0",
      "3d18d589901d499e9a2352df144b77fb",
      "cdc1ef5deb8e473cb4eaf9d9f5ecef64",
      "060cef9d20b64f1b8cf525755d22efb1",
      "fcedfcc8f0004297a4fd0571c57df020",
      "14c3f3b9e5594955b2dc17dad178bb9e",
      "4c4753dc34804c3185f72943ffb040d3",
      "18ea0c3af55b4a979d7bab017963aad2",
      "8e127e2cc54d45dbbb77b02f4bf01a50",
      "06e123c78a734ef0b48f85d53e9c91b7",
      "07753ecae6de4ab08264b8480418978b",
      "6c13ffe74dc941048894ec7f5ae62e4a",
      "76fcd105792e4a3e8151b1efa4fca123",
      "0d1fdfec1fce4f5e99d464e36ce2c841",
      "edcc72eb322f456fad1ea5226c43dd1d",
      "8a0113ee025d4edc86d612935508a6a9",
      "30008056639a4e7580097a4542b25e60",
      "953f8455ea184bf2b33b6dff672c0473",
      "713ed31fe0234b2bafbf9d1751e2aadb",
      "f01f461bff014e84a293af6d374e7566",
      "fbbcbd1f2fb24baf9b76dd661d526927",
      "d9323c77b1154ad89dc08241640be134",
      "868613042ef748b08d0937d0c2804d86",
      "015b848f966e48828d4ca04d9700233b",
      "4a8dedacc43a46869b097da5f93188a0",
      "f5d4f99feca248088ff1788101774191",
      "2e5c1174b4a6409f834fb476ed965344",
      "17fc654edea74a6f88443a633c8b4ad2",
      "b46c274809b641e79a746aa37c05c8c1",
      "50d7dc5a1c2b46fc885f5b0ff6ae79cb",
      "44e642f5106743838a71939392b544d2",
      "b9c5272ecf0343eaaa10cb34f4c44b3d",
      "82567761978044a9a0bfcb289b7828d7",
      "69f8e3faf13f4a958b3f669df85b15f4",
      "ad9147aab77744d7b0f6541e1401704f",
      "3e34d6e0183a421f85e14df098adb5ea",
      "73344c56e06f42e0a7f3888aa6e4c119",
      "6f527eab3ecc48e5a286c4af63a859c4",
      "51a12759de65463a8cc331cdcd57d12a",
      "0ac1ac74c98b4bdf82a4257103d78582",
      "4ad7cc4b8c9644bf9796f9de4e789a59",
      "7e1b27462cfc4f10b6732976259b4231",
      "055a39da98dd44e388d8483696776054",
      "b4660eb0daa048dca9f0d92767d88f22",
      "cafc7f9fee1c4057a5e8b15f991d1198",
      "7975acfcf45e4913aea5b29c6f98eb7c",
      "2b251aec0c7e4634894b564f6c76e52a",
      "4afafe3667fb4158af2dadabb4e28929",
      "a1bf2c5b55874bc5b6cab73cf7e7fd63",
      "8d9a6fc9bbb4496186d31d9f156850a0",
      "cf5c1faeb82c4b91b0306b13553647e8",
      "7d7c98ed04cd45cb9666621b8ec8fc49",
      "2dd7d5566ae84754acd2a878e5d64ae1",
      "54026b1ee8d144a98bca5319e010b794",
      "d0a1fb0b4c824d1c8c9cb77cf6b3b660",
      "a779d3fffeb941c5b5557251f98cee1f",
      "339c7007044f4d2b85938b26c3dbffd0",
      "0dfcd10f504745c68bb98d5f4bdf8cc2",
      "597add1c266e48ff8fc0a72e2c7dd7ce",
      "2a09e4653b1245459f5be0f957a65742",
      "09abbfb64fe949a9a2733bee16edeffa",
      "f870aad817604c319d703f11c5b75f7d",
      "7a1cd560236a400b881be8ad1122f94b",
      "0ef48c94e653419ab35b851b18f9eb19",
      "2d7e07621ad346278b73bcdaebeecd0b",
      "df0f4e3020b0463fa1deef7d59ab2ca4",
      "886872897ee4461b8184cfd352b168e5",
      "12f123de3b234bd7ba2238ad10ff04a4",
      "8ccfed216627474982e383994f61ceaa",
      "d90d4082d7f54e4585a1bdc964d35644",
      "f15931e5ec6c4e368dd243d5fed3ff75",
      "84c02b3fe92e49a5946da3bc50f1229d",
      "c6fbcb13ee224b369a887cfb05dbc917",
      "a15054a344e743b5ae7d53afec3e0c32",
      "a45257e3191d4cce8e0f63400cad1119",
      "2a2559d8252e4f028659d7e6791ef516",
      "743632e38d0b4470907c27ed4a4e41f1",
      "ca84fc6e9f6d46629db21c155d07b66f",
      "1d367208d08847e395bda136a86dff5f",
      "cb22d42995a5490983fd4bcc5c59dbb7",
      "99fb1b714273494bb7cff985cd7ffc2f",
      "2a2aa097a6914de5bfc0c80b34add3a7",
      "da78433524a44031bea2f7eb49bb777b",
      "86f9cfea78ba482cb2303f7b4881dd66",
      "b3a04320424c402da5290c6549ce35ab",
      "6b148efa07914552bde74546aeb0e753",
      "cfe7c64f08e8475dbda8490558e206b1",
      "25b51168e25e407691c9e13471396f67",
      "212d56157e904bef9d958bb7f1f85d7a",
      "9dd8e30f7692434aaaf751bddd655a69",
      "257912e4c40d46bc93497382bb67c531",
      "23f60e10bab14ec6a545a86a1e30126a",
      "fabd87a4ef3d445db502b65b4a58ecb7",
      "8a4766d07de2458fa024b2d2823b8281",
      "2e6ecf24ed4b423d8b9f57be04160477",
      "0fd4df0d714b4aaeb4f83b0c7d3c2904",
      "9c96df3bc42d49a99df483411e1e4e0e",
      "e5f3f0a335ed4df98d2404ccce3470e9",
      "a9f355ee4f7e47508e734bde921c9fb7",
      "09d772f6e5564e219f37268069a10d10",
      "6c2a41c2306e40df8ed03a2802f7e568",
      "b5449a8db52e43e880843722cb4c6579",
      "0f088567fbe64aeda160abc0adb0120e",
      "7e50626654774431b688042b71f81180",
      "ae23c6ccdd8849978f77267b5d05c649",
      "91dd4351da5b483cb5fa2e617a88bcfe",
      "b34c41f4bff44b80bd07ac4f233e92b0",
      "a5546b434c36464987e333e54ad77e41",
      "b68ff18c59cf4ce196ec99efbd85e8da",
      "58a0b5e8ad77478ea7e7bd95c831c970",
      "cabd84fe8b50431b9a07092e18b9af2e",
      "0117acb737ad423ea92a3a41b0bfc5d2",
      "d981a0eb24874024b857d6e50838e815",
      "8983703064794e89a7d313e983ec9921",
      "245f0b71ccf1483e97f8cc8aebc2e673",
      "a011d76829544cb9a83afcb24666da0a",
      "5684852a2228452ca25c95155d3a0c19",
      "d8cceb3437284365a867bcf79ecd6ddf",
      "a9dc4eeba0ed4f9f9ff46756bd2b1ecb",
      "6b50333dee6a417eae25273a182d4ddd",
      "47024867afd2473fb327ef74ec059a31",
      "af2c82d3b429463693a1fb86c2992802",
      "3c94eb8bb77b4c6788ae4480d24b7a18",
      "4ce87861946f4f9f924027f90ecaaffa",
      "aa65f4456b5a4c36b2308fb71a23819b",
      "24bb2cfb09a548fa9e4a14accd426317",
      "8d9d185d4b5f44c1978b91ecc004f38a",
      "77e644c575bf476a962158e8a75e6f9a",
      "c0d8fd62bef34f3db7f9711746fd066b",
      "b88db73dc2af4762b0b408fa83c51284",
      "8b5a2ef1ecdb4586a13770cf7cff5891",
      "61009ac488b24e4485d1bedec4ad1917",
      "ea59214a584349c4b38395cec6f79003",
      "63b9943d56de4ab89ebb39d0ff5ade4a",
      "a62bf22f75a842ee8620b2f5fbf191a9",
      "71203c5899bc4318b91449076e7477aa",
      "1394679061154a25b2894fb4bca6eed6",
      "615082d8d248497e98118b526899d533",
      "fe893333b9bc41338a79620373ca6c40",
      "b72adae7f71346c981e8dafc8c144956",
      "e98e0895ec6f41d89508c8c6d4ddeb08",
      "b7f921e7ed244c3e9bc1f23f38858507",
      "59999771407b42efaf9dd75df07d9cfc",
      "54d4f740ff9b48e899303b8e62c9763a",
      "d1f3c45adbcb4deb914ff4244288707e",
      "16b3e199383946c2a27445fbbffe8036",
      "829b60cba2804b11974b6c591435bc97",
      "47dfff9f2fa745c4bd96dbc8bc50ab6e",
      "6bb14391ac3f491998ecd6cb572bfa8a",
      "2c14852e5c7b4161b156e920b9168446",
      "1519bd8fc0944983ad9e9cbcfa23b412",
      "38fc7d38387b43258469ffb6c64728d7",
      "abef368228f442cf9417273eb3440bec",
      "9113537c70ed4356b8eb33956a623718",
      "de345b85f9104be0ab2c460d65fa1ab9",
      "5873cf41002841c5affac9e057cd03ff",
      "5347cf9491c442bfb97fb675f58d24c7",
      "1bf6a79ab2574450942d0314e8d4344b",
      "45789eeb01cf46faa96fc3847f9973f4",
      "fcccda5921b84139ab30e9d81c976c7b",
      "bc651b5a7b40444e85e87b2c8458eff3",
      "237ddfb07b9a4ebdbcac00d3e72cca37",
      "246a3b07a29c441d906e48bed42d0023",
      "295a94fdbd004349b4f919e3cd01ad09",
      "618e463e676e4edebc3b302d0e5fbb70",
      "d8e6beb81c9f4092b703c051ec205bbd",
      "b24f4c4f3cc342318681d0e6ae9fdca9",
      "fa7778014bd1480aa6f8004be48ab996",
      "b7234cbb3d0f43eb86dc754d65bce979",
      "0d6e317b8c9b4ab19bb9111dab4bd70e",
      "977880c44b384ccbab6262c94c8d5c4d",
      "1439c16bad7b4471a0ea5b91818918fe",
      "fda89125c5f54680924d36c68909600c",
      "baaaa6c004de422aac72d3843895ef53",
      "c4112d934db14d98b1232d2a131bedbd",
      "a583af6fa86645379dfab2e82d01b953",
      "330c5a2cbe0e4062bffcb4b87d0947ac",
      "11aaa04806b845679beeae2c5a166d2b",
      "73e9042533c046dd9b69e5e35d0fe0f5",
      "7067e1b7b82840848f0059d54f076ca4",
      "267cccaa1fb64e1495751335eaaf06cc",
      "13f55aa7f659473280c7a6e762867fdd",
      "4d2b9eda0b2747a383bb6da82d042206",
      "952a498280274cb69edf70c956cb94d8",
      "8b3739a57609409595a5dd2a3052a122",
      "38231d584bbc4352838af7b59426dbee",
      "71b13b9aa5024a259e01eb8737a588a1",
      "592042ac230e42e48b211c6c2c73db6b",
      "8ddcf92330f24f6ba1c87a3524b38643",
      "e942d61c9b5848e3aa21e8e27bcac788",
      "5f6db5cd07da46bea59b597470bdae5f",
      "e2ce79922ceb4e5b986f76820e590fa9",
      "0e17220a085148c48b29894f3ed854d4",
      "bbc79ae6c96340a7829eb2fb9e5b6def",
      "8b9c4d8b8705490c90013c321231d35e",
      "7c0e129084454e25b311d1dcbfba86e3",
      "c8f8ae1414b74740814f6b63064b88b4",
      "a378b47000644adc9ecf427dcb54a4f9",
      "6b81adba8e2342e4af326b5708d315d7",
      "8edddfd7ee4143fba858fba3f5ef9019",
      "b371b90e8e774d018b3aa7390f808e5a",
      "85a60607d9a1436db07dfc54c876882c",
      "20cb0a363165447d83c94a51fb23c851",
      "a64a5a0e23494cce908812729c91a062",
      "9f41ad909db04aea9d13d36b581e1035",
      "88c280bd290941d69a3ad16cda86f75a",
      "6a3a39d1744743439c3aa4646dbe1645",
      "0107de95dfd147bbb66a7f3f31da09f9",
      "08a300b8411e4ad486d3602f3b85e850",
      "4140a790921c4209b901f747a397f2af",
      "3384d3bcf9da4809acef25f2957c3297",
      "75cd9fa84055448c8d85fd62a648860b",
      "4aef1eb2d11e4fe68a4c0460259e7d06",
      "c3a2987d3be147cab8b0497715676258",
      "72523176b8464117ace586bceb2812cb",
      "f0bb7d3c9e904e3f9a1cefeeb26714ac",
      "508a08fea02e4e169eb19c8c7a47b9a7",
      "2e2cca9507b34eed8b86a1100cb0447c",
      "6a46a44fc98d4fcca40c558fac332a45",
      "d153cdff30524561b102487a901b7fa0",
      "dd1d02cddba34ba29e4f7cf49ca70c82",
      "4cec3c7ff93b4639a9d22435e80849b2",
      "ba29af05b37144f0ae7080f9e0f21330",
      "d320f7824c194d68b8dc5358c5622b08",
      "51a3a9e6ab5f4fc0bf6d74128d7431dc",
      "c41ec18725f9467fb6494f06835385f9",
      "68cf4799fac94b58b9f09446ddb9b821",
      "e3c27f40c3ee4fa29d026abe9e28be22",
      "66445808ca7844c683366c1c6d6ce65c",
      "303f3dedf2324982b0c54bc548984762",
      "c4e5f09e913243e4bff17adeb29490b0",
      "14d425b5594b4110a24d31195fcccd0b",
      "24d09e76016049d18e662d7865302511",
      "bad1fb1ca63c40a3a1ad2da43db1aba9",
      "e43c457cbee248c4843d331ed6ef8718",
      "044d9007727a4acebc2c489ecc2a6b8f",
      "898ac81dd6a44b6b89c5e4a73370ba6d",
      "bc1a96e43f0b43d1a857eb28c8db8494",
      "a3e37ce171fb450ca65e57e8adc75d50",
      "63e0bcc3d29249dd8118272c7a8cf681",
      "ed3341ad6fb940cd85dfba5b2aa80591",
      "7f397cdc6e1f48bc92ac0c42b237f131",
      "38f206160d14443b9227a5bc36b92309",
      "cb668efeabd64f229b9ac3306eadd997",
      "e9afcbdc8b3549c88a583ae41fce7ccd",
      "453e2a68838948989fdc0429c604bbf6",
      "e05e1e4476e24162aa9ed63255fa0330",
      "d05baa72150848c0bb6c5c7425eff20c",
      "23ab866b7aa94fdfb8104e2f80a00942",
      "5944990ddb6c4b22bd0f61ed7d1b662b",
      "af6c30f0349940ee9c6389fe97b95d30",
      "0aa1969904ae4db39c46093b308ba317",
      "6c47afcc6c4c459096e62381d07235a0",
      "f54de204732e4c9887c3daa4f632d48e",
      "8088531d8a4e4435846c833d5e8aa02a",
      "34438d43fdc54c8c8ba051b41a4152ba",
      "5b0697af8eda44a9858cbe3a912eb71e",
      "50983a900e0c4bf5b2d7214c79b9947c",
      "07c484beca944d6d9441ec5819296c37",
      "749ad1b30f58473e891f113e83547c62",
      "d4872c8e743e4b2b8af61778624cd2d5",
      "9ea626b8752e410daf4ca6b011a9aa84",
      "ea4f4458744341d884fdbed0b66193e5",
      "7992b4c5afdc4f339c0537be688be2e3",
      "52f610e537214424ab0f0ba559d656b2",
      "d2ea88a1a1bb42b6afb502911eb5aa0b",
      "3977ce0abb0641058914c11fe3123847",
      "8d435fae96a44221b1caa85dec479288",
      "bb77f46d86ee4d2f8d0c9bb231358e47",
      "d449879fb772450990b637d15d2eca97",
      "44afb613126548b7af55d1221a894b74",
      "9c5706ee7edf4983966dcd0ed2776c79",
      "b2999ed74e56488a9069abddaaaad401",
      "196fdb13033b48e9938f18e3ed8e6516",
      "488332526a33440498bbf82a3fefaab4",
      "315b283151b74387990180b0bd5f86c5",
      "b020c0d483914bb7bdd6df8255b0d327",
      "0b15846e5eaf4d0fb00ba420c95cc06c",
      "a57141661ac9400eb9dc03ed30e93e70",
      "c188898482cd4edf819157261b8b1e98",
      "3c788083cba141c792707b6f94cd7912",
      "0bbc7e2dd4be42e7aaf1ca43dd5e8a6a",
      "272c7cb95c7b4138adedf5dc3acc818c",
      "5387cd52f1d1418983acb89ab0654a5b",
      "77d61fa65a884193a066c2349a0b1dbe",
      "692d575f757c4d7f8478e40eee06c1db",
      "c52694b0af634a009024bd4bc9f261f3",
      "1d8f9a18c1b841f2beca0097b10bc121",
      "58dbfa1c153e47d7a9312280a8ca69d9",
      "48eaa796ea3c4017830e1077546e20b6",
      "b740be1264d94b50af82ae1e1d5d9427",
      "df49966215244d67818b31763a0a04d6",
      "28c317c5a79745e8b41bcb75dba01e30",
      "bac6c1987858401e92de75c11a3bee5a",
      "7d9a200c90f542c28b1a443914790b36",
      "4fd29fee5b93477491158d8ceb47589b",
      "608201a97b9c4ba59b1ea27439b910e0",
      "868e80e7148041faa7939dbfadc11137",
      "f6b0ea4cd1dd47aaa8996bba52833476",
      "aa19daad1e824e3a8d85a8ae363de592",
      "1e11ddf88e014afdb64cbc296ac71ade",
      "e482ba03df1244c7a8e29bfbf7291eff",
      "244861cc08a743a3afa6591b727a103d",
      "4b079f39a9b6463780fcf14441d892e9",
      "63d496cc650f4257a69923622183eda5",
      "341a67be2bfb46d69c0b8cd8324f5114",
      "474ae3d23dc3427e9cd40407dcff90cb",
      "9d51a3572e0d4283ba4e2e1a5cb8ff69",
      "fad53768da7142889f16fd7b235c7a7d",
      "6208f51b2dfc4b029f32f598ee4ee6b7",
      "347102722969495a8bcc85051daf01e7",
      "28282002920443bbb216edb4cb304ba6",
      "3677bd3965814b66912012e14997faef",
      "266f73d47cb14c758680494aac19ce8c",
      "43a9fc5ac9c94e0e9bd764025891e2f8",
      "4db6a406b4324fa294c739c1a2891383",
      "251638ecb72f42088f1ddbd5fdc98c79",
      "f4e64f777b7847f599b06457f2928297",
      "d6ca20264d5a49a5b4c9b4c2d27a4e6e",
      "53be344293c24039b81a01c8fc4c7c40",
      "8798d7b5356c4171b9f1eae3229c49fd",
      "30cae1d6345a4e48b4cc80dc3916c7ed",
      "35d29139d0204f04b7410bdc05af08d6",
      "016746b2e081486cb8123e281dae1ee5",
      "cd0e7d69a5774e359f5f86e6bbf7cb85",
      "153579d57fde4c878a6e842f4be287c7",
      "f8cf437b092d4c17967fc23c4d3e0c09",
      "2c88edb1d7a54de2a82186d073494984",
      "20052cd0e7064211b95879c760e927a3",
      "7fcd05c5b07d417383ee56e57f678ac8",
      "316f129428bc46739d15abe6a8e22435",
      "d83ec8ff863b473aaaf042d70518ca12",
      "afde5a6131a740199331013aa68d88bb",
      "1205a08105bf4abdac0e7069c69624c1",
      "ffbd9852abec420ab5f71c8aadaa36a9",
      "b6389f0c600d403ab993b171c11e89f8",
      "8f86098fbbce4979b87b6b9551ca6a45",
      "8f12236121da44008618a4609f17aeb3",
      "46a295fa665642f0a9b19c2b6af6624a",
      "2ecd462eab9b46fe95009814e648e5a3",
      "7f44dd19a2d1412ba2633f71ae171a16",
      "285234cc91f14f8ba010e75486a4658c",
      "663cd800269e4349bb0b70fec5a27e57",
      "e892f9df81c542ccb378d8c0fa3c999e",
      "e60975bb2c62435eaaf4871f7966faa7",
      "bcff0aa2521242b9b68227550cb8d269",
      "5575b916dc4d4d6d9adae32efb357397",
      "f88711e4a97540a1b2ab84a0756a62f7",
      "635e8d93bc784d518b5bf44f9d2db2f2",
      "2979044f90664a7594e2992b2bae3a32",
      "6050165ef78848d5b76ee5f978aa6266",
      "21b933c922884d8ebd98723aace2c8ce",
      "536a15dfc3df446c9ef79ba04c2e43b2",
      "4b37322c539244aa8ec8f48d8ff5e890",
      "a1426f74cad74037b4092f03c2a33694",
      "d61aeb4fb7014e93944467a40161817e",
      "22e4ef22821943e1990a435b6ad425a7",
      "67b04088b687495282dc0567de0764cf",
      "536c9315ab77408aa25d619907fea055",
      "0bd156e12612429fb31e435f5cb00eb9",
      "89dbbf4aebb5437f8bad29850a7806f7",
      "3a5342a3cacb416a8b97e83fc3e32bf0",
      "c47f85a7e45b40d5a2d8b8476e060a84",
      "bef35c2c08654e61bfa420aed3bf84f2",
      "07414bced7eb4f7d939c2e6d52515f81",
      "c6084924b7da42879ef7a3037f992770",
      "a82bc10491bb416282b76a96cab9d2ea",
      "b4e8c9b3f4114adbbf51f5765880afef",
      "2dbb464f50c24a9684ed65bd202eead7",
      "62e0705695454baa8ab4c27d914bc339",
      "b4bade2b98344f7f82d3969728c5ae3e",
      "a54e121694e4454a96a23639203db8a0",
      "14ab460b3c2b4af0972319a626ca63fe",
      "92ec71f24ba44fe1a5021f9d05449181",
      "375c88c7be544f7abbe24e63313fee51",
      "9602e07a4f0c4206b107ad43991535a3",
      "bef2196ed7e94ec4b149b330c738c2f4",
      "096843d374cd4b81ab1aa3da9c28f295",
      "b06930b01a8e48afacecbe5103ac3383",
      "ef2ef1b197594663beb6d3cbf01f78ea",
      "8d0f292ad7cf474b9e0649be832a2cc2",
      "beb57e3476f9442aaf0a710ab51a6810",
      "d65b36cdb8564957a1cb8d1fe9057a0c",
      "8788ad1bbef74787a1ee5cac169e094c",
      "76f9330e169a44f2a62468b4bcfb1c97",
      "dd27968086a646a89b5e011d338efb9d",
      "1aacf5d806e3421087f00771021acffc",
      "3cca054a0203417cbabb97272db80c91",
      "099960e4e2a44135baf4778c5ca4b631",
      "78d0279c30bd45d383ddef0f3c4eb232",
      "58c6940281534b85975847d75820899e",
      "0183835d319744118a91a05a20c79b19",
      "7f3540dfbde74054a57f7c9f5941b934",
      "c5fa4113988c41b1bbddb5e08d4c8352",
      "3dc516955173435db630906e389a8199",
      "32c6fbd840bc4bd082f6388901bf066a",
      "e8cae494a2d94c73b6eb442d5e82fb6e",
      "f28c664cd34b4e8e8a966384282a1804",
      "a5e122a36a7d44e0b81616e37a7fc85c",
      "51e4de59498c4d66bba8e03741062a79",
      "dc8d8d523dd14ef791ad31efc2a796d4",
      "fa0a1f53bc8d42fb85bfa52bebc7bdf3",
      "b5379d97daf34975bd98be1f5eefcd6d",
      "5436a99ed4e14e2a9ef0783e54e0db5c",
      "2dc6865c4c2c40a58cb3ba87da00f186",
      "de24178d20c74862ba8ff22a5ffa22f0",
      "e9935c3528924095834e65b11296222c",
      "85294e2d2b00485b8f4beddd62971e96",
      "67b0da02bbee45d8856259eb018bee6e",
      "42dfe8d4fe714766abcd34f1f8f7d874",
      "a7e5f7d35a6d43fea024bb4e2fc4a134",
      "229e24dc626b4f4aabde2f58ed7ea2ce",
      "67c6b872b00d4875beecea28709b4a68",
      "88049cd864164aa1afe45924eb950cc0",
      "95812a3b303e469cacfd9999b4e55c97",
      "58d6cbfadd434bbe871289774aee9d4b",
      "8abca2b024f44436822da3093c6bde36",
      "ba861cf132d84a26b31391c5947d58c8",
      "dfc5bd6503654ed3b753517f63d66d14",
      "ba359788beb94ed98d91059201e62a9e",
      "c80816a2c0dc491ca536d7793cb40eed",
      "6ca8920f8048488d9a21a196e0c0319f",
      "9ad9f34e6a5c4002a011cf73e8f37084",
      "21da7534323147ecbcac277ee710f0c4",
      "d4a329c3c06840cba636ed43250886c8",
      "db2b7603cc7b4966ad5026b14f1df1ba",
      "bb005a36671246528e0a0bd1c1f91cc6",
      "58ce01a4e00348d1bd548d6614b85e1f",
      "78b9109b4d7a4be993e233f99e5e4eef",
      "850cc67bea984d2898e4b5c9e27875b3",
      "f2a7e61d6e7e4fbe81beb3986cd5ba66",
      "4707556919fa465fb0c8bed09996315d",
      "b5d5b593e03d480b99bd3e61574209c3",
      "6c36ca13bdbd4052a7ffe6c488925962",
      "5138668786724d589f798522a3c2e08d",
      "be82e8cb388c48bebe5e37329e30c385",
      "a0c45eb025614fc4babbc4d304fe1d78",
      "0fc01be342334d8ca8507ff88514a86d",
      "f881a75ed4964ce1912552a47fdbf859",
      "3f40ab197595438fafd4535c4dca5165",
      "a54f328a276543e69cc99cc53031b6d0",
      "5ece02abe4db4b0a8e6eb2feea6b0dec",
      "de065adc629743b1a6dba076d892bf03",
      "4ce971b7c11a47be9d49371b5b71b0b9",
      "f97cca5d9c2e483c891c55f762392250",
      "5b57b60e52bc479d93b1a323d2c0d668",
      "cdaa19aa593c4138b3a7999bba2a87a0",
      "c17cb80885e44801b973acfa5c4a4de7",
      "cb94887224a245cfaf758d5a4743ec5e",
      "53f47f57cc2c4568ab5cfc4d834683e9",
      "de8ceb8b164241ec8c0014ba2b5beba1",
      "1d422d305d1143ff9abd643c927e17ab",
      "c9cbb74822904f7987224eb025707575",
      "541bc0ef83314c70a0da05324a95d7b5",
      "f329de659f49420b812ece91a296b63a",
      "e4f8734fa3604d14bae20609671f8464",
      "92e1be1349214bf089948b33b9a1c508",
      "4d6fe6ff34114177ad36ec6ee61c41af",
      "2d09b97813d045e9b4739018190ddc13",
      "acfdcbf4824d448d93f654d2e2c71437",
      "089827db025847aba95ced743cf34ea6",
      "050cc9f6fb2d4ab5b593f70b01fe1162",
      "fca1c3517edd4fca8f59ed92611e7c4c",
      "ea9b6861604b471d9ac13d5af47e15a0",
      "0410c82a99474a1387626af970cee247",
      "2d163b67b5b949909a745d7d76474bb9",
      "e283797368a04fcb933625fb4c2c6661",
      "cceeda172fc34e97b84db5276be1b1f2",
      "dc46ace3f7804d18bd476a7e30a6a428",
      "6941c935acc445f4b68cb72f67f9f035",
      "3ee9cf1bf70d49c4a5909df9774cc109",
      "b2fe92ebd2a542d4b56c31007abdb03a",
      "3421d1d1f2534397afd8e6019f9c764c",
      "40898895e578409892b7d2d7998fe709",
      "e06975102b144637bb5c789b384be288",
      "e8120d9de19f414a85d6c527a9872b9a",
      "3ba804ac21a84d789df61764493868e6",
      "5f82d878cf414edf825c9fca2618bb49",
      "d19f18dc770e4ad9906986977474567f",
      "8ad1586634694a3f99a6c30f734331c0",
      "d1510739c1f74e27b1ee5dbde629f6a9",
      "39007b5b27a84643b4ce4cf167de519e",
      "ea68ed6d060b4dbc9fba7bb982367ad5",
      "e8fb023f733846c2ab27d87481e33918",
      "1acc2fd88ac444b484488a59c99975cb",
      "115577f8af54480c8d68587fdaa48e58",
      "fdf7901d5b3e4035a768d6adb23fbbba",
      "b57ed76f4c8a4656ba140623401e6677"
     ]
    },
    "id": "ldm3ZeMFcjNi",
    "outputId": "5c34d000-0453-4815-8778-7b1972c80b54"
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1d67d617b9b24a458443046a056861bc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7408115f17f746089339c637287b01a4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "933da30f23ec4b89a8818ffaf01cc1e3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1b5c8ce0ff84bdba7c9c324acf20d68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4e32c0cc336b4c0d83192e16ee512907",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fb33d2751a16416fad5af4aa03c9b780",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fcedfcc8f0004297a4fd0571c57df020",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8a0113ee025d4edc86d612935508a6a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2e5c1174b4a6409f834fb476ed965344",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6f527eab3ecc48e5a286c4af63a859c4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1bf2c5b55874bc5b6cab73cf7e7fd63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a09e4653b1245459f5be0f957a65742",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f15931e5ec6c4e368dd243d5fed3ff75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2a2aa097a6914de5bfc0c80b34add3a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fabd87a4ef3d445db502b65b4a58ecb7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7e50626654774431b688042b71f81180",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "245f0b71ccf1483e97f8cc8aebc2e673",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24bb2cfb09a548fa9e4a14accd426317",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1394679061154a25b2894fb4bca6eed6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "47dfff9f2fa745c4bd96dbc8bc50ab6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "45789eeb01cf46faa96fc3847f9973f4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0d6e317b8c9b4ab19bb9111dab4bd70e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "267cccaa1fb64e1495751335eaaf06cc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2ce79922ceb4e5b986f76820e590fa9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "20cb0a363165447d83c94a51fb23c851",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3a2987d3be147cab8b0497715676258",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "51a3a9e6ab5f4fc0bf6d74128d7431dc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "044d9007727a4acebc2c489ecc2a6b8f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e05e1e4476e24162aa9ed63255fa0330",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "50983a900e0c4bf5b2d7214c79b9947c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb77f46d86ee4d2f8d0c9bb231358e47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c188898482cd4edf819157261b8b1e98",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b740be1264d94b50af82ae1e1d5d9427",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e482ba03df1244c7a8e29bfbf7291eff",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3677bd3965814b66912012e14997faef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "016746b2e081486cb8123e281dae1ee5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ffbd9852abec420ab5f71c8aadaa36a9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bcff0aa2521242b9b68227550cb8d269",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "22e4ef22821943e1990a435b6ad425a7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b4e8c9b3f4114adbbf51f5765880afef",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b06930b01a8e48afacecbe5103ac3383",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78d0279c30bd45d383ddef0f3c4eb232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc8d8d523dd14ef791ad31efc2a796d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "229e24dc626b4f4aabde2f58ed7ea2ce",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9ad9f34e6a5c4002a011cf73e8f37084",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6c36ca13bdbd4052a7ffe6c488925962",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f97cca5d9c2e483c891c55f762392250",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e4f8734fa3604d14bae20609671f8464",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e283797368a04fcb933625fb4c2c6661",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f82d878cf414edf825c9fca2618bb49",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Processed prompts:   0%|          | 0/1 [00:00<?, ?it/s, est. speed input: 0.00 toks/s, output: 0.00 toks/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Avg sentences : 28.32\n",
      "95th-pct sentences : 39.29999999999998\n",
      "Avg tokens     : 235.22\n",
      "95th-pct tokens: 250.0\n"
     ]
    }
   ],
   "source": [
    "# Measure sentence & token stats for the model's own ToT outputs on 50 test Qs\n",
    "from datasets import load_dataset\n",
    "import re, statistics, numpy as np\n",
    "from vllm import SamplingParams\n",
    "\n",
    "N            = 50\n",
    "sample_ds    = load_dataset(\"openai/gsm8k\", \"main\", split=f\"test[:{N}]\")\n",
    "sent_lens    = []\n",
    "token_lens   = []\n",
    "\n",
    "sp = SamplingParams(temperature=0.3, top_p=1.0, max_tokens=250)\n",
    "for ex in sample_ds:\n",
    "    q  = ex[\"question\"]\n",
    "    p  = tokenizer.apply_chat_template(\n",
    "            [{\"role\":\"system\",\"content\":\"You are a helpful assistant.\"},\n",
    "             {\"role\":\"user\",\"content\":q}],\n",
    "            tokenize=False, add_generation_prompt=True\n",
    "         )\n",
    "    txt = model.fast_generate(p, sampling_params=sp,\n",
    "                              lora_request=lora_handle)[0].outputs[0].text\n",
    "    # crude split: one sentence ≈ ends with period or newline\n",
    "    sent_lens.append(len(re.split(r\"[.\\n]\", txt)))\n",
    "    token_lens.append(len(tokenizer(txt).input_ids))\n",
    "\n",
    "print(\"Avg sentences :\", statistics.mean(sent_lens))\n",
    "print(\"95th-pct sentences :\", np.percentile(sent_lens, 95))\n",
    "print(\"Avg tokens     :\", statistics.mean(token_lens))\n",
    "print(\"95th-pct tokens:\", np.percentile(token_lens, 95))\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
